"""
Workflow Engine - åŸºäºç”¨æˆ·æä¾›çš„ MVP æ¶æ„å®ç°
æ”¯æŒèŠ‚ç‚¹ç±»å‹: MessageTrigger, AI, UpdateDB, Delay, SendWhatsAppMessage, Template, GuardrailValidator

æ¨¡å—è¯´æ˜:
- è´Ÿè´£è§£æå¹¶æ‰§è¡Œå·¥ä½œæµå®šä¹‰ï¼ˆnodes + edgesï¼‰ï¼ŒæŒ‰é¡ºåºåˆ›å»ºå¹¶è°ƒç”¨å¯¹åº”çš„ NodeProcessorã€‚
- ç®¡ç† `WorkflowContext`ï¼Œåœ¨èŠ‚ç‚¹é—´ä¼ é€’ `trigger_data`ã€`ai.reply`ã€`ai.analyze`ã€`db` ç­‰ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
- å°† AIService å’Œ WhatsAppService é›†æˆåˆ°èŠ‚ç‚¹ä¸­ï¼š
  - AIProcessor è°ƒç”¨ AIService ä»¥è·å–ç»“æ„åŒ–ç»“æœå¹¶æŠŠ `ai.reply.reply_text` å†™å…¥ä¸Šä¸‹æ–‡ï¼›
  - SendWhatsAppMessageProcessor ä»ä¸Šä¸‹æ–‡è¯»å–æ¶ˆæ¯å†…å®¹å¹¶è°ƒç”¨ WhatsAppService å‘é€ï¼ŒåŒæ—¶è®°å½•æ¶ˆæ¯åˆ°æ•°æ®åº“ï¼›
  - UpdateDBProcessor å°† AI åˆ†æç»“æœåº”ç”¨åˆ° `customers` è¡¨å¹¶å†™å®¡è®¡æ—¥å¿—ã€‚
- æä¾›é”™è¯¯æ•è·ã€æ­¥éª¤æ‰§è¡Œè®°å½•ï¼ˆWorkflowExecution / WorkflowStepExecutionï¼‰ä¸ä¹è§‚é”/é‡è¯•æ”¯æŒã€‚

æ³¨æ„:
- ä¿®æ”¹èŠ‚ç‚¹è¾“å…¥/è¾“å‡º schema æˆ–æ–°å¢èŠ‚ç‚¹ç±»å‹æ—¶ï¼Œåº”åŒæ—¶æ›´æ–°æœ¬æ¨¡å—ä¸­çš„å¤„ç†å™¨æ˜ å°„ `self.processors` ä¸ç›¸å…³æ–‡æ¡£ã€‚
- AI èŠ‚ç‚¹æœŸæœ› `AIService.generate_combined_response` è¿”å›ç»“æ„åŒ– JSONï¼ˆanalyze, reply, metaï¼‰ï¼Œæ¨¡å—ä¼šå¤„ç†çº¯æ–‡æœ¬ fallbackã€‚

"""

import asyncio
import json
import logging
import random # ä¿®å¤: å¯¼å…¥ random æ¨¡å—
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Union
from sqlalchemy.orm import Session
from app.db.models import (
    Workflow, WorkflowExecution, WorkflowStepExecution, 
    Customer, Message, AIAnalysis, AuditLog, CustomEntityRecord # å¯¼å…¥ CustomEntityRecord
)
from app.services.ai_service import AIService
from app.services.whatsapp import WhatsAppService
import pytz
import re
from app.services.telegram import TelegramService
import uuid
import time

logger = logging.getLogger(__name__)

class WorkflowContext:
    """å·¥ä½œæµæ‰§è¡Œä¸Šä¸‹æ–‡"""
    def __init__(self):
        self.variables = {}
        self.chat = {}
        self.actor = {}
        self.db = {}
        self.versions = {}
        self.scheduled_at = None
        self.message_id = None
        self.sent_at = None
        self.ai = {} # æ–°å¢ ai ä¸Šä¸‹æ–‡

    def set(self, key: str, value: Any):
        self.variables[key] = value

    def get(self, key: str, default=None):
        return self.variables.get(key, default)

    def update_from_dict(self, data: Dict[str, Any]):
        self.variables.update(data)

    def to_dict(self) -> Dict[str, Any]:
        """è¿”å›ä¸Šä¸‹æ–‡çš„å­—å…¸è¡¨ç¤º"""
        return self.variables

class NodeProcessor:
    """èŠ‚ç‚¹å¤„ç†å™¨åŸºç±»"""
    
    def __init__(self, db: Session, context: WorkflowContext):
        self.db = db
        self.context = context
        
    async def execute(self, node_config: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒèŠ‚ç‚¹å¹¶è¿”å›è¾“å‡º"""
        raise NotImplementedError

class MessageTriggerProcessor(NodeProcessor):
    """æ¶ˆæ¯è§¦å‘å™¨èŠ‚ç‚¹"""
    
    async def execute(self, node_config: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†æ¶ˆæ¯è§¦å‘"""
        channel = node_config.get("channel", "whatsapp")
        match_key = node_config.get("match_key", "Phone")
        
        # ä»è§¦å‘æ•°æ®ä¸­è·å–æ¶ˆæ¯ä¿¡æ¯
        trigger_data = self.context.get("trigger_data", {})
        
        if channel == "whatsapp" and match_key == "Phone":
            phone = trigger_data.get("phone")
            message_content = trigger_data.get("message")
            
            # ğŸ”’ å¾è§¸ç™¼æ•¸æ“šç²å– user_id
            user_id = trigger_data.get("user_id")
            if not user_id:
                logger.error("Workflow trigger missing user_id")
                raise ValueError("Workflow trigger missing user_id")
            
            # ğŸ”’ ç²å–å±¬æ–¼ç‰¹å®šç”¨æˆ¶çš„å®¢æˆ¶ä¿¡æ¯
            customer = self.db.query(Customer).filter(
                Customer.phone == phone,
                Customer.user_id == user_id
            ).first()
            
            if not customer:
                # ğŸ”’ å‰µå»ºæ–°å®¢æˆ¶æ™‚è¨­ç½®æ­£ç¢ºçš„ user_id
                customer = Customer(
                    phone=phone,
                    name=phone,  # ä¸´æ—¶ä½¿ç”¨ç”µè¯å·ç ä½œä¸ºåå­—
                    status="active",
                    user_id=user_id
                )
                self.db.add(customer)
                self.db.commit()
                self.db.refresh(customer)
            
            # ğŸ”’ è·å–èŠå¤©å†å²ï¼ˆæœ€è¿‘5æ¡ï¼Œåƒ…é™è©²ç”¨æˆ¶ï¼‰
            chat_history = self.db.query(Message).filter(
                Message.customer_id == customer.id,
                Message.user_id == user_id
            ).order_by(Message.timestamp.desc()).limit(5).all()
            
            # æ›´æ–°ä¸Šä¸‹æ–‡
            self.context.chat["last_message"] = message_content
            self.context.chat["history"] = [
                {"content": msg.content, "direction": msg.direction} 
                for msg in reversed(chat_history)
            ]
            self.context.actor["phone"] = phone
            self.context.db["customer"] = customer
            
            return {
                "ctx.chat.last_message": message_content,
                "ctx.chat.history": self.context.chat["history"],
                "ctx.actor.phone": phone
            }
        
        raise ValueError(f"Unsupported channel: {channel} or match_key: {match_key}")

class AIProcessor(NodeProcessor):
    """AI èŠ‚ç‚¹ - é›†æˆåˆ†æå’Œå›å¤ç”Ÿæˆ"""
    
    def __init__(self, db: Session, context: WorkflowContext):
        super().__init__(db, context)
        # å»¶è¿Ÿåˆå§‹åŒ– AIServiceï¼Œå…ˆä¿ç•™ db_sessionï¼›åœ¨ execute æ—¶æ ¹æ®ä¸Šä¸‹æ–‡åˆ›å»º ai_service
        self.db_session = db
        self.ai_service = None
    
    async def _get_chat_history(self, customer_id: str, message_count: int, include_timestamps: bool = False) -> str:
        """
        è·å–å®¢æˆ·çš„èŠå¤©å†å²è®°å½•
        
        Args:
            customer_id: å®¢æˆ·ID
            message_count: è·å–çš„æ¶ˆæ¯æ¡æ•°
            include_timestamps: æ˜¯å¦åŒ…å«æ—¶é—´æˆ³
            
        Returns:
            æ ¼å¼åŒ–çš„èŠå¤©å†å²å­—ç¬¦ä¸²
        """
        try:
            from app.db.models import Message
            from datetime import datetime
            
            # è·å–æœ€è¿‘çš„æ¶ˆæ¯è®°å½•
            messages = self.db.query(Message).filter(
                Message.customer_id == customer_id
            ).order_by(Message.timestamp.desc()).limit(message_count).all()
            
            if not messages:
                return ""
            
            # åè½¬é¡ºåºï¼Œä½¿æœ€æ—©çš„æ¶ˆæ¯åœ¨å‰
            messages.reverse()
            
            # æ ¼å¼åŒ–èŠå¤©å†å²
            history_lines = []
            for msg in messages:
                # ç¡®å®šå‘é€è€…
                sender = "å®¢æˆ·" if msg.direction == "inbound" else "AI"
                
                # æ ¼å¼åŒ–æ—¶é—´æˆ³
                if include_timestamps:
                    timestamp = msg.timestamp.strftime("%Y-%m-%d %H:%M")
                    line = f"[{timestamp}] {sender}: {msg.content}"
                else:
                    line = f"{sender}: {msg.content}"
                
                history_lines.append(line)
            
            return "\n".join(history_lines)
            
        except Exception as e:
            logger.error(f"Failed to get chat history: {e}")
            return ""
    
    async def execute(self, node_config: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œ AI åˆ†æå’Œå›å¤ç”Ÿæˆ"""
        print(f"\nğŸ¤– AIç¯€é»é–‹å§‹åŸ·è¡Œ...")
        print(f"  ç¯€é»é…ç½®: {node_config}")
        
        try:
            # è·å–æ–°çš„é…ç½®
            model_config = node_config.get("model", {
                "name": "gpt-4o-mini", 
                "temperature": 0.7, 
                "max_tokens": 500
            })
            
            # ğŸ”§ ä¿®å¾©ï¼šå¾ data å­—æ®µç²å– prompt é…ç½®
            node_data = node_config.get("data", {})
            
            # è·å–å®¢æˆ·æ•°æ®ä»¥ç¡®å®šé˜¶æ®µ
            customer = self.context.db.get("customer")
            
            # ä½¿ç”¨æ•°æ®åº“ä¸­å­˜å‚¨çš„ system_prompt ä½œä¸ºåŸºç¡€ prompt
            raw_system_prompt = node_data.get("system_prompt", node_config.get("system_prompt", "You are a professional AI assistant."))
            raw_user_prompt = node_data.get("user_prompt", node_config.get("user_prompt", "Please reply to the user's message."))
            
            # ğŸ”§ è§£æ System Prompt ä¸­çš„å˜é‡
            base_system_prompt = await self._resolve_prompt_variables(raw_system_prompt)
            user_prompt = await self._resolve_prompt_variables(raw_user_prompt)

            # ğŸ”§ å¤„ç†èŠå¤©å†å²é…ç½®
            chat_history_config = node_data.get("chat_history", {})
            chat_history_text = ""
            
            if chat_history_config.get("enabled", False):
                # ä¼˜å…ˆä½¿ç”¨æ¥è‡ª WhatsApp ç½‘å…³çš„èŠå¤©å†å²
                trigger_data = self.context.get("trigger_data", {})
                gateway_chat_history = trigger_data.get("chat_history", [])
                
                if gateway_chat_history:
                    message_count = chat_history_config.get("message_count", 10)
                    include_timestamps = chat_history_config.get("include_timestamps", False)
                    
                    print(f"  ğŸ“š ä½¿ç”¨ç½‘å…³èŠå¤©å†å²: {len(gateway_chat_history)}æ¡æ¶ˆæ¯, é™åˆ¶: {message_count}æ¡, æ—¶é—´æˆ³: {include_timestamps}")
                    
                    # é™åˆ¶æ¶ˆæ¯æ•°é‡
                    limited_history = gateway_chat_history[-message_count:] if message_count > 0 else gateway_chat_history
                    
                    # æ ¼å¼åŒ–èŠå¤©å†å²
                    history_lines = []
                    for msg in limited_history:
                        sender = "å®¢æˆ·" if msg.get("direction") == "inbound" else "AI"
                        content = msg.get("content", "")
                        
                        if include_timestamps and msg.get("timestamp"):
                            # æ ¼å¼åŒ–æ—¶é—´æˆ³
                            from datetime import datetime
                            try:
                                timestamp = datetime.fromisoformat(msg["timestamp"].replace("Z", "+00:00"))
                                time_str = timestamp.strftime("%Y-%m-%d %H:%M")
                                line = f"[{time_str}] {sender}: {content}"
                            except:
                                line = f"{sender}: {content}"
                        else:
                            line = f"{sender}: {content}"
                        
                        history_lines.append(line)
                    
                    chat_history_text = "\n".join(history_lines)
                    print(f"  âœ… ç½‘å…³èŠå¤©å†å²å¤„ç†æˆåŠŸ: {len(history_lines)}è¡Œ")
                
                elif customer:
                    # å›é€€åˆ°æ•°æ®åº“æŸ¥è¯¢ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
                    message_count = chat_history_config.get("message_count", 10)
                    include_timestamps = chat_history_config.get("include_timestamps", False)
                    
                    print(f"  ğŸ“š å›é€€åˆ°æ•°æ®åº“æŸ¥è¯¢èŠå¤©å†å²: {message_count}æ¡æ¶ˆæ¯, æ—¶é—´æˆ³: {include_timestamps}")
                    chat_history_text = await self._get_chat_history(
                        customer.id, 
                        message_count, 
                        include_timestamps
                    )
                    
                    if chat_history_text:
                        print(f"  âœ… æ•°æ®åº“èŠå¤©å†å²è·å–æˆåŠŸ: {len(chat_history_text.split(chr(10)))}è¡Œ")
                    else:
                        print(f"  âš ï¸ æœªæ‰¾åˆ°èŠå¤©å†å²è®°å½•")
                
                # å°†èŠå¤©å†å²æ·»åŠ åˆ° user_prompt
                if chat_history_text:
                    user_prompt = f"èŠå¤©å†å²è®°å½•:\n{chat_history_text}\n\nå½“å‰ç”¨æˆ·æ¶ˆæ¯: {user_prompt}"

            # åŠ¨æ€æ‹¼æ¥ system_promptï¼Œå¦‚æœ enableHandoff ä¸º true
            enable_handoff = node_data.get("enableHandoff", False)
            if enable_handoff:
                print("  âœ… Handoff enabled: Dynamically appending confidence and JSON instructions to system_prompt.")
                # è¿™é‡Œæ³¨å…¥è¯¦ç»†çš„ JSON æ ¼å¼å’Œ confidence æŒ‡å¯¼
                system_prompt = f"""{base_system_prompt} You MUST return ONLY valid JSON (no extra text before or after).

CRITICAL: Your response must be valid JSON following this exact schema:

{{
  "analyze": {{
    "updates": {{}},
    "uncertain": [],
    "reason": "Brief explanation for your confidence level (1-2 sentences)",
    "confidence": 0.0
  }},
  "reply": {{
    "reply_text": "Your helpful response to the customer",
    "followup_questions": [],
    "suggested_tags": []
  }},
  "meta": {{
    "used_profile": "ai_assistant",
    "separator": "|||",
    "safe_to_send_before_db_update": true,
    "handoff": {{
      "triggered": false,
      "reason": null,
      "confidence": 0.0
    }}
  }}
}}

CONFIDENCE SCORING (MANDATORY - DO NOT use 0.0 unless truly uncertain):
- 0.0-0.2: Cannot answer / No relevant information / Complete uncertainty
- 0.3-0.5: Some uncertainty / Partial information / Need clarification  
- 0.6-0.8: Good confidence / Clear information available
- 0.9-1.0: Very high confidence / Exact factual answer / Direct evidence

HANDOFF LOGIC:
- Set "handoff.triggered": true if you cannot provide a helpful answer
- Set "handoff.triggered": false if you can provide a useful response
- Always set "handoff.confidence" to match your "analyze.confidence"
- In "analyze.reason", briefly explain why you chose that confidence level

EXAMPLES:
- Real estate question with clear answer â†’ confidence: 0.8-0.9, handoff: false
- Vague inquiry needing clarification â†’ confidence: 0.4-0.6, handoff: false  
- Completely unrelated topic â†’ confidence: 0.1-0.2, handoff: true
- Technical issue you cannot help with â†’ confidence: 0.0-0.1, handoff: true

Remember: Return ONLY the JSON. No markdown, no explanations, just valid JSON."""
            else:
                system_prompt = base_system_prompt
                print("  âŒ Handoff not enabled: Using base system_prompt without confidence/JSON instructions.")

            print(f"  ğŸ“ æœ€ç»ˆ System Prompt: {system_prompt}")
            print(f"  ğŸ“ User Prompt: {user_prompt}")
            print(f"  Model Config: {model_config}")
            
            # ç¡®ä¿ä¸Šä¸‹æ–‡ä¸­æœ‰ customerï¼ˆå®¹é”™ï¼šå¦‚æœ MessageTrigger æ²¡å…ˆè¿è¡Œï¼‰
            if not self.context.db.get("customer"):
                trigger = self.context.get("trigger_data", {})
                phone = trigger.get("phone")
                user_id = trigger.get("user_id")
                if phone and user_id:
                    try:
                        cust = self.db.query(Customer).filter(Customer.phone == phone, Customer.user_id == user_id).first()
                        if cust:
                            self.context.db["customer"] = cust
                    except Exception:
                        pass

            # åˆå§‹åŒ– ai_serviceï¼ˆç”¨æœ€æ–°çš„ user_idï¼‰
            if not self.ai_service:
                customer = self.context.db.get("customer")
                user_id = customer.user_id if customer else None
                self.ai_service = AIService(db_session=self.db_session, user_id=user_id)

            # è§£æç”¨æˆ·promptä¸­çš„å˜é‡
            resolved_user_prompt = await self._resolve_prompt_variables(user_prompt)
            # print(f"  è§£æå¾Œçš„ User Prompt: {resolved_user_prompt}") # Duplicate print
            
            # ğŸ”§ ä¿®å¾©ï¼šå˜—è©¦ä½¿ç”¨çœŸæ­£çš„ OpenAI APIï¼Œå¦‚æœå¤±æ•—å‰‡ä½¿ç”¨æ¨¡æ“¬
            try:
                print(f"  ğŸš€ å˜—è©¦èª¿ç”¨ OpenAI API...")
                print(f"  API Key å¯ç”¨: {bool(self.ai_service and self.ai_service.api_key)}")
                
                if self.ai_service and self.ai_service.api_key and self.ai_service.client:
                    print(f"  ğŸ“¡ ç™¼é€è«‹æ±‚åˆ° OpenAI...")
                    # è·å–åª’ä½“è®¾ç½®
                    media_settings = node_data.get("media_settings", {})
                    llm_response = await self.ai_service.generate_combined_response(
                        system_prompt=system_prompt,
                        user_prompt=resolved_user_prompt,
                        model=model_config.get("name", "gpt-4o-mini"),
                        temperature=model_config.get("temperature", 0.7),
                        max_tokens=model_config.get("max_tokens", 900),
                        media_settings=media_settings
                    )
                    print(f"  âœ… OpenAI API å›å¾©: {llm_response.get('reply', {}).get('reply_text', '')}")
                    
                    # ç¾åŒ–å¹¶æ‰“å°å®Œæ•´çš„LLMè¾“å‡º
                    try:
                        import json
                        # print("--- å®Œæ•´çš„LLMåŸå§‹è¾“å‡º (ç¾åŒ–JSON) ---") # Remove verbose LLM output print
                        # print(json.dumps(llm_response, indent=2, ensure_ascii=False)) # Remove verbose LLM output print
                        # print("--- LLMåŸå§‹è¾“å‡ºç»“æŸ ---") # Remove verbose LLM output print
                    except Exception as e:
                        print(f"  âš ï¸ æ‰“å°LLMåŸå§‹è¾“å‡ºå¤±è´¥: {e}")

                    # æå– confidence
                    ai_confidence = llm_response.get("analyze", {}).get("confidence", 0.0)
                    
                    # æ ¹æ®AIç½®ä¿¡åº¦è¿›è¡ŒHandoffåˆ¤æ–­ï¼Œå¹¶è®¾ç½®åˆ†æ”¯
                    handoff_threshold = node_data.get("handoff_threshold", 0.6)
                    
                    should_handoff = enable_handoff and (ai_confidence <= handoff_threshold)
                    
                    # æ›´æ–° context.ai å¹¶è¿”å›åˆ†æ”¯
                    self.context.ai['reply'] = llm_response.get("reply", {})
                    self.context.ai['analyze'] = llm_response.get("analyze", {})
                    self.context.ai['meta'] = llm_response.get("meta", {})
                    self.context.ai['prompt_used'] = {"system": system_prompt, "user": resolved_user_prompt}
                    self.context.ai['api_used'] = "openai"
                    
                    # ä¿å­˜ AI åˆ†æç»“æœåˆ°æ•°æ®åº“
                    customer = self.context.db.get("customer")
                    message = self.db.query(Message).filter(Message.customer_id == customer.id).order_by(Message.timestamp.desc()).first()
                    
                    if customer: # åªæœ‰å½“æœ‰å®¢æˆ·æ—¶æ‰ä¿å­˜åˆ†æç»“æœ
                        ai_analysis = AIAnalysis(
                            customer_id=customer.id,
                            message_id=message.id if message else None, # å¯ä»¥ä¸ºç©º
                            analysis_type="extract_and_reply",
                            input_data={"system_prompt": system_prompt, "user_prompt": resolved_user_prompt},
                            output_data=llm_response,
                            confidence=ai_confidence,
                            model_used=model_config.get("name", "gpt-4o-mini"),
                            handoff_triggered=should_handoff, # å­˜å‚¨ handoff çŠ¶æ€
                            handoff_reason=llm_response.get("meta", {}).get("handoff", {}).get("reason", "") if should_handoff else None, # å­˜å‚¨ handoff åŸå› 
                            user_id=customer.user_id # ç¡®ä¿ user_id è¢«è®¾ç½®
                        )
                        self.db.add(ai_analysis)
                        self.db.commit()
                        self.db.refresh(ai_analysis)

                    # ğŸ”§ ä¿®å¾©: handoff è§¸ç™¼æ™‚èµ° false åˆ†æ”¯åˆ°æ¨¡æ¿ç¯€é»ï¼Œä¸è§¸ç™¼æ™‚èµ° true åˆ†æ”¯åˆ° AI å›å¾©ç¯€é»
                    branch = "false" if should_handoff else "true"
                    self.context.set(f"__branch__{node_config['id']}", branch)
                    print(f"  Handoff enabled: {enable_handoff}, Confidence: {ai_confidence}, Threshold: {handoff_threshold}, Triggered: {should_handoff}, Branch: {branch}")
                    # Add the ai context to the variables dictionary for propagation
                    self.context.variables['ai'] = self.context.ai 

                    # Also store AI output under node ID for direct reference
                    self.context.variables[f'{node_config["id"]}.output'] = {
                        "reply_text": llm_response.get("reply", {}).get("reply_text", ""),
                        "analyze": llm_response.get("analyze", {}),
                        "meta": llm_response.get("meta", {})
                    }

                    return self.context.to_dict()
                else:
                    print(f"  âš ï¸ æ²’æœ‰å¯ç”¨çš„ OpenAI API Key æˆ–å®¢æˆ¶ç«¯æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨æ¨¡æ“¬å›å¾©")
                    # æ¨¡æ‹ŸAIå›å¤ï¼ˆå¦‚æœçœŸæ­£çš„APIä¸å¯ç”¨ï¼‰
                    ai_reply_text = "æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚"
                    llm_response = {
                        "analyze": {
                            "updates": {},
                            "uncertain": [],
                            "reason": "OpenAI API not available or client not initialized",
                            "confidence": random.uniform(0.3, 0.9) # éšæœºç”Ÿæˆç½®ä¿¡åº¦
                        },
                        "reply": {
                            "reply_text": ai_reply_text,
                            "followup_questions": [],
                            "suggested_tags": []
                        },
                        "meta": {
                            "used_profile": "mock_ai_response",
                            "separator": "|||",
                            "safe_to_send_before_db_update": True
                        }
                    }
                    
                    # Determine if handoff should be triggered based on mock confidence
                    mock_confidence = llm_response["analyze"]["confidence"]
                    should_handoff = enable_handoff and (mock_confidence < handoff_threshold)
                    
                    # ğŸ”§ ä¿®å¾©: handoff è§¸ç™¼æ™‚èµ° false åˆ†æ”¯åˆ°æ¨¡æ¿ç¯€é»ï¼Œä¸è§¸ç™¼æ™‚èµ° true åˆ†æ”¯åˆ° AI å›å¾©ç¯€é»
                    branch = "false" if should_handoff else "true"
                    self.context.set(f"__branch__{node_config['id']}", branch)
                    print(f"  Handoff enabled: {enable_handoff}, Confidence: {mock_confidence}, Threshold: {handoff_threshold}, Triggered: {should_handoff}, Branch: {branch}")

                    # Update ai context with mock response
                    self.context.ai.update(**llm_response)
                    self.context.ai["prompt_used"] = {"system": system_prompt, "user": user_prompt}
                    self.context.ai["api_used"] = "mock_openai"
                    self.context.variables['ai'] = self.context.ai
                    self.context.variables[f'{node_config["id"]}.output'] = {
                        "reply_text": llm_response.get("reply", {}).get("reply_text", ""),
                        "analyze": llm_response.get("analyze", {}),
                        "meta": llm_response.get("meta", {})
                    }
                    return self.context.to_dict()
            except Exception as api_error:
                print(f"  âŒ OpenAI API èª¿ç”¨å¤±æ•—: {api_error}")
                print(f"  éŒ¯èª¤é¡å‹: {type(api_error).__name__}")
                logger.error(f"OpenAI API call failed: {api_error}")
            
            # æ¨¡æ‹ŸAIå›å¤ï¼ˆå¦‚æœçœŸæ­£çš„APIä¸å¯ç”¨ï¼‰
            ai_reply_text = "æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚"
            llm_response = {
                "analyze": {
                    "updates": {},
                    "uncertain": [],
                    "reason": f"OpenAI API call failed: {type(api_error).__name__}",
                    "confidence": random.uniform(0.3, 0.9) # éšæœºç”Ÿæˆç½®ä¿¡åº¦
                },
                "reply": {
                    "reply_text": ai_reply_text,
                    "followup_questions": [],
                    "suggested_tags": []
                },
                "meta": {
                    "used_profile": "error_fallback",
                    "separator": "|||",
                    "safe_to_send_before_db_update": True
                }
            }
            
            # Determine if handoff should be triggered based on fallback confidence
            fallback_confidence = llm_response["analyze"]["confidence"]
            should_handoff = enable_handoff and (fallback_confidence < handoff_threshold)
            
            # ğŸ”§ ä¿®å¾©: handoff è§¸ç™¼æ™‚èµ° false åˆ†æ”¯åˆ°æ¨¡æ¿ç¯€é»ï¼Œä¸è§¸ç™¼æ™‚èµ° true åˆ†æ”¯åˆ° AI å›å¾©ç¯€é»
            branch = "false" if should_handoff else "true"
            self.context.set(f"__branch__{node_config['id']}", branch)
            print(f"  Handoff enabled: {enable_handoff}, Confidence: {fallback_confidence}, Threshold: {handoff_threshold}, Triggered: {should_handoff}, Branch: {branch}")

            # Update ai context with fallback response
            self.context.ai.update(**llm_response)
            self.context.ai["prompt_used"] = {"system": system_prompt, "user": user_prompt}
            self.context.ai["api_used"] = "error_fallback"
            self.context.variables['ai'] = self.context.ai
            self.context.variables[f'{node_config["id"]}.output'] = {
                "reply_text": llm_response.get("reply", {}).get("reply_text", ""),
                "analyze": llm_response.get("analyze", {}),
                "meta": llm_response.get("meta", {})
            }
            return self.context.to_dict()
        except Exception as e:
            # æ•è· execute æ–¹æ³•ä¸­çš„ä»»ä½•æœªå¤„ç†å¼‚å¸¸ï¼Œç¡®ä¿æ–¹æ³•æœ‰å®Œæ•´çš„ try/except ç»“æ„
            print(f"  âŒ AI è™•ç†å¤±æ•—: {e}")
            logger.error(f"AI processing failed: {e}")

            # æ„é€ ä¸€ä¸ªå®‰å…¨çš„å›é€€ ai ä¸Šä¸‹æ–‡
            error_reply = {"reply_text": "æŠ±æ­‰ï¼ŒAIå¤„ç†å‡ºç°é—®é¢˜ï¼Œæˆ‘ä»¬ä¼šå°½å¿«å›å¤æ‚¨ã€‚", "followup_questions": [], "suggested_tags": []}
            error_analyze = {"updates": {}, "confidence": 0.0, "uncertain": [], "reason": f"AIå¤„ç†å¤±è´¥: {e}"}
            error_meta = {"handoff": {"triggered": False, "reason": "AIå¤„ç†é”™è¯¯", "confidence": 0}}

            try:
                self.context.ai['reply'] = error_reply
                self.context.ai['analyze'] = error_analyze
                self.context.ai['meta'] = error_meta
                # ä¿è¯ prompt_used å­—æ®µå­˜åœ¨ï¼ˆå¦‚æœåœ¨ä¸Šæ–‡å®šä¹‰è¿‡ system_prompt/user_prompt åˆ™ä½¿ç”¨ï¼‰
                if 'system_prompt' in locals() and 'user_prompt' in locals():
                    self.context.ai['prompt_used'] = {"system": system_prompt, "user": user_prompt}
                self.context.ai['api_used'] = "error"
                self.context.variables['ai'] = self.context.ai
                self.context.variables[f'{node_config["id"]}.output'] = {
                    "reply_text": error_reply['reply_text'],
                    "analyze": error_analyze,
                    "meta": error_meta
                }
            except Exception:
                # å¦‚æœæ„å»ºå›é€€ä¸Šä¸‹æ–‡å¤±è´¥ï¼Œä»ç„¶è¿”å›ä¸€ä¸ªæœ€å°ç»“æ„ï¼Œé¿å…æŠ›å‡ºäºŒæ¬¡å¼‚å¸¸
                return {
                    "ai.reply": error_reply,
                    "ai.analyze": error_analyze,
                    "ai.meta": error_meta,
                    f"__branch__{node_config.get('id')}": "false"
                }

            return self.context.to_dict()

    async def _resolve_prompt_variables(self, prompt: str) -> str:
        """è§£æ prompt ä¸­çš„å˜é‡å¹¶è¿”å›è§£æåçš„å­—ç¬¦ä¸²

        æ”¯æŒå˜é‡: {{trigger.name}}, {{trigger.phone}}, {{trigger.content}}, {{trigger.timestamp}},
        ä»¥åŠ {{db.customer.<field>}}ã€‚
        """
        resolved_prompt = prompt or ""
        
        # print(f"  ğŸ” è§£æ Prompt å˜é‡å‰: {resolved_prompt[:100]}...") # Remove verbose pre-resolution print

        try:
            # è·å–è§¦å‘å™¨æ•°æ®
            trigger_data = self.context.get("trigger_data", {}) or {}
            # print(f"  ğŸ“ è§¦å‘å™¨æ•°æ®: {trigger_data}") # Remove verbose trigger data print

            # ä¿®æ­£å­—æ®µæ˜ å°„ï¼šæ¨¡æ¿ä¸­ä½¿ç”¨ contentï¼Œä½†è§¦å‘å™¨ä¸­ä¸º message
            if "{{trigger.name}}" in resolved_prompt:
                name_value = str(trigger_data.get("name", ""))
                resolved_prompt = resolved_prompt.replace("{{trigger.name}}", name_value)
                # print(f"    - æ›¿æ¢ {{{{trigger.name}}}} -> '{name_value}'")
                
            if "{{trigger.phone}}" in resolved_prompt:
                phone_value = str(trigger_data.get("phone", ""))
                resolved_prompt = resolved_prompt.replace("{{trigger.phone}}", phone_value)
                # print(f"    - æ›¿æ¢ {{{{trigger.phone}}}} -> '{phone_value}'")
                
            if "{{trigger.content}}" in resolved_prompt:
                content_value = str(trigger_data.get("message", ""))
                resolved_prompt = resolved_prompt.replace("{{trigger.content}}", content_value)
                # print(f"    - æ›¿æ¢ {{{{trigger.content}}}} -> '{content_value}'")
                
            if "{{trigger.timestamp}}" in resolved_prompt:
                timestamp_value = str(trigger_data.get("timestamp", ""))
                resolved_prompt = resolved_prompt.replace("{{trigger.timestamp}}", timestamp_value)
                # print(f"    - æ›¿æ¢ {{{{trigger.timestamp}}}} -> '{timestamp_value}'")

            # å®¢æˆ·å­—æ®µæ›¿æ¢
            customer = self.context.db.get("customer")
            if customer:
                if "{{db.customer.name}}" in resolved_prompt:
                    customer_name = str(getattr(customer, "name", ""))
                    resolved_prompt = resolved_prompt.replace("{{db.customer.name}}", customer_name)
                    # print(f"    - æ›¿æ¢ {{{{db.customer.name}}}} -> '{customer_name}'")
                    
                if "{{db.customer.phone}}" in resolved_prompt:
                    customer_phone = str(getattr(customer, "phone", ""))
                    resolved_prompt = resolved_prompt.replace("{{db.customer.phone}}", customer_phone)
                    # print(f"    - æ›¿æ¢ {{{{db.customer.phone}}}} -> '{customer_phone}'")
                    
                if "{{db.customer.status}}" in resolved_prompt:
                    customer_status = str(getattr(customer, "status", ""))
                    resolved_prompt = resolved_prompt.replace("{{db.customer.status}}", customer_status)
                    # print(f"    - æ›¿æ¢ {{{{db.customer.status}}}} -> '{customer_status}'")
                    
                if "{{db.customer.email}}" in resolved_prompt:
                    customer_email = str(getattr(customer, "email", ""))
                    resolved_prompt = resolved_prompt.replace("{{db.customer.email}}", customer_email)
                    # print(f"    - æ›¿æ¢ {{{{db.customer.email}}}} -> '{customer_email}'")

        except Exception as err:
            print(f"  âš ï¸ è§£æ prompt å˜é‡å¤±è´¥: {err}")

        print(f"  âœ… è§£æ Prompt å˜é‡å: {resolved_prompt[:100]}...")
        return resolved_prompt
    
    async def _simulate_ai_response(self, system_prompt: str, user_prompt: str, model_config: dict) -> str:
        """æ¨¡æ‹ŸAIå“åº”ï¼ˆå®é™…åº”è¯¥è°ƒç”¨OpenAI APIï¼‰"""
        import random
        
        trigger_data = self.context.get("trigger_data", {})
        user_message = trigger_data.get("content", "")
        user_name = trigger_data.get("name", "å®¢æˆ·")
        
        # æ ¹æ®æ¶ˆæ¯å†…å®¹å’Œsystem promptç”Ÿæˆç›¸åº”çš„å›å¤
        if "æˆ¿åœ°äº§" in system_prompt or "æˆ¿æº" in system_prompt:
            if "æˆ¿" in user_message or "price" in user_message.lower():
                responses = [
                    f"æ‚¨å¥½{user_name}ï¼æ„Ÿè°¢æ‚¨å¯¹æˆ‘ä»¬æˆ¿æºçš„å…³æ³¨ã€‚æˆ‘ä»¬æœ‰å¤šä¸ªä¼˜è´¨é¡¹ç›®ï¼Œä»·æ ¼ä»å‡ åä¸‡åˆ°å‡ ç™¾ä¸‡ä¸ç­‰ã€‚è¯·é—®æ‚¨çš„é¢„ç®—èŒƒå›´å’Œåå¥½åŒºåŸŸæ˜¯ä»€ä¹ˆï¼Ÿæˆ‘å¯ä»¥ä¸ºæ‚¨æ¨èæœ€åˆé€‚çš„æˆ¿æºã€‚",
                    f"Hi {user_name}! æˆ‘ä»¬ç›®å‰æœ‰å¾ˆå¤šçƒ­é—¨æˆ¿æºã€‚ä¸ºäº†ç»™æ‚¨æœ€ç²¾å‡†çš„æ¨èï¼Œèƒ½å‘Šè¯‰æˆ‘æ‚¨çš„è´­æˆ¿é¢„ç®—å’Œå¿ƒä»ªåŒºåŸŸå—ï¼Ÿ",
                    f"æ‚¨å¥½ï¼å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚å…³äºæˆ¿æºä¿¡æ¯ï¼Œæˆ‘ä»¬æœ‰æ–°ç›˜å’ŒäºŒæ‰‹æˆ¿ä¸¤ç§é€‰æ‹©ã€‚æ‚¨æ›´å€¾å‘äºå“ªç§ç±»å‹å‘¢ï¼Ÿ"
                ]
            elif "è°¢è°¢" in user_message or "thank" in user_message.lower():
                responses = [
                    f"ä¸å®¢æ°”{user_name}ï¼å¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–æˆ¿äº§é—®é¢˜ï¼Œéšæ—¶è”ç³»æˆ‘ä»¬ã€‚",
                    f"å¾ˆé«˜å…´èƒ½å¸®åˆ°æ‚¨ï¼æœ‰ä»»ä½•è´­æˆ¿éœ€æ±‚éƒ½å¯ä»¥æ‰¾æˆ‘ä»¬ã€‚",
                    f"æ‚¨å¤ªå®¢æ°”äº†ï¼è¿™æ˜¯æˆ‘ä»¬åº”è¯¥åšçš„ï¼Œç¥æ‚¨æ—©æ—¥æ‰¾åˆ°å¿ƒä»ªçš„æˆ¿æºã€‚"
                ]
            else:
                responses = [
                    f"æ‚¨å¥½{user_name}ï¼æˆ‘æ˜¯æ‚¨çš„ä¸“å±æˆ¿äº§é¡¾é—®ã€‚å…³äºæ‚¨çš„å’¨è¯¢ï¼Œæˆ‘ä¼šä¸ºæ‚¨æä¾›æœ€ä¸“ä¸šçš„å»ºè®®ã€‚è¯·é—®æ‚¨æ˜¯æƒ³äº†è§£å“ªä¸ªåŒºåŸŸçš„æˆ¿æºå‘¢ï¼Ÿ",
                    f"Hi {user_name}ï¼æ„Ÿè°¢æ‚¨é€‰æ‹©æˆ‘ä»¬ã€‚æˆ‘ä¼šæ ¹æ®æ‚¨çš„éœ€æ±‚ä¸ºæ‚¨æ¨èæœ€åˆé€‚çš„æˆ¿äº§é¡¹ç›®ã€‚",
                    f"æ‚¨å¥½ï¼å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚ä½œä¸ºä¸“ä¸šçš„æˆ¿äº§é¡¾é—®ï¼Œæˆ‘ä¼šå…¨åŠ›ååŠ©æ‚¨æ‰¾åˆ°ç†æƒ³çš„æˆ¿æºã€‚"
                ]
        else:
            # é€šç”¨å›å¤
            if "è°¢è°¢" in user_message or "thank" in user_message.lower():
                responses = [
                    f"ä¸å®¢æ°”{user_name}ï¼å¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–é—®é¢˜ï¼Œéšæ—¶è”ç³»æˆ‘ä»¬ã€‚",
                    f"å¾ˆé«˜å…´èƒ½å¸®åˆ°æ‚¨ï¼æœ‰ä»»ä½•éœ€è¦éƒ½å¯ä»¥æ‰¾æˆ‘ä»¬ã€‚",
                    f"æ‚¨å¤ªå®¢æ°”äº†ï¼è¿™æ˜¯æˆ‘ä»¬åº”è¯¥åšçš„ã€‚"
                ]
            else:
                responses = [
                    f"æ‚¨å¥½{user_name}ï¼æ„Ÿè°¢æ‚¨çš„å’¨è¯¢ã€‚æˆ‘å·²ç»æ”¶åˆ°æ‚¨çš„æ¶ˆæ¯ï¼Œä¼šæ ¹æ®æ‚¨çš„éœ€æ±‚ä¸ºæ‚¨æä¾›æœ€é€‚åˆçš„å»ºè®®ã€‚",
                    f"Hi {user_name}ï¼æˆ‘ä»¬å·²ç»æ”¶åˆ°æ‚¨çš„æ¶ˆæ¯ã€‚ä¸ºäº†æ›´å¥½åœ°ä¸ºæ‚¨æœåŠ¡ï¼Œè¯·é—®æ‚¨å…·ä½“éœ€è¦ä»€ä¹ˆå¸®åŠ©å‘¢ï¼Ÿ",
                    f"æ‚¨å¥½ï¼å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚å…³äºæ‚¨æåˆ°çš„é—®é¢˜ï¼Œæˆ‘ä¼šå°½å¿«ç»™æ‚¨è¯¦ç»†å›å¤ã€‚"
                ]
        
        return random.choice(responses)

class UpdateDBProcessor(NodeProcessor):
    """æ•°æ®åº“æ›´æ–°èŠ‚ç‚¹"""
    
    async def execute(self, node_config: Dict[str, Any]) -> Dict[str, Any]:
        """æ›´æ–°æ•°æ®åº“"""
        table = node_config.get("table", "customers")
        match_key = node_config.get("match_key", "Phone")
        ops = node_config.get("ops", [])
        optimistic_lock = node_config.get("optimistic_lock", {"enabled": True})
        skip_if_equal = node_config.get("skip_if_equal", True)
        
        if table != "customers":
            raise ValueError(f"Unsupported table: {table}")
        
        customer = self.context.db.get("customer")
        if not customer:
            raise ValueError("Customer not found in context")
        
        # è·å– AI åˆ†æç»“æœ
        ai_analyze = self.context.get("ai.analyze", {})
        updates = ai_analyze.get("updates", {})
        
        if not updates and skip_if_equal:
            return {"db.updated_row": customer, "ctx.versions.db": customer.version}
        
        # ä¹è§‚é”æ£€æŸ¥
        if optimistic_lock.get("enabled", True):
            current_version = customer.version
            expected_version = optimistic_lock.get("incoming_version", current_version)
            
            if current_version != expected_version:
                conflict_strategy = optimistic_lock.get("on_conflict", "prompt")
                if conflict_strategy == "abort":
                    raise ValueError("Version conflict detected")
                # å…¶ä»–å†²çªå¤„ç†ç­–ç•¥å¯ä»¥åœ¨è¿™é‡Œå®ç°
        
        # è®°å½•æ—§å€¼ç”¨äºå®¡è®¡
        old_values = {
            "move_in_date": customer.move_in_date.isoformat() if customer.move_in_date else None,
            "custom_fields": customer.custom_fields.copy()
        }
        
        # åº”ç”¨æ›´æ–°
        has_changes = False
        new_values = {}
        
        for op in ops:
            col = op.get("col")
            value = op.get("value")
            mode = op.get("mode", "set")
            
            if col == "move_in_date" and "Move-In Date" in updates:
                try:
                    new_val = datetime.strptime(updates["Move-In Date"], "%Y-%m-%d").date()
                    if customer.move_in_date != new_val:
                        customer.move_in_date = new_val
                        new_values["move_in_date"] = new_val.isoformat()
                        has_changes = True
                except ValueError:
                    logger.warning(f"Invalid date format: {updates['Move-In Date']}")
                    
            elif col == "custom_fields" and mode == "merge_json":
                # åˆå¹¶è‡ªå®šä¹‰å­—æ®µ
                custom_updates = {k: v for k, v in updates.items() if k.startswith("Custom:")}
                if custom_updates:
                    current_custom = customer.custom_fields.copy()
                    current_custom.update(custom_updates)
                    customer.custom_fields = current_custom
                    new_values["custom_fields"] = custom_updates
                    has_changes = True
                    
            elif col == "last_follow_up_time" and mode == "now":
                customer.last_follow_up_time = datetime.utcnow()
                new_values["last_follow_up_time"] = datetime.utcnow().isoformat()
                has_changes = True
        
        if has_changes:
            # æ›´æ–°ç‰ˆæœ¬å·å’Œæ—¶é—´æˆ³
            customer.version += 1
            customer.updated_at = datetime.utcnow()
            
            # è®°å½•å®¡è®¡æ—¥å¿—
            audit_log = AuditLog(
                entity_type="customer",
                entity_id=customer.id,
                action="update",
                old_values=old_values,
                new_values=new_values,
                user_id=customer.user_id,
                source="workflow"
            )
            self.db.add(audit_log)
            
            self.db.commit()
            self.db.refresh(customer)
        
        return {
            "db.updated_row": customer,
            "ctx.versions.db": customer.version
        }

class DelayProcessor(NodeProcessor):
    """å»¶è¿ŸèŠ‚ç‚¹ - æ§åˆ¶å·¥ä½œæ—¶æ®µå’Œé™é¢‘"""
    
    async def execute(self, node_config: Dict[str, Any]) -> Dict[str, Any]:
        """è®¡ç®—å»¶è¿Ÿæ—¶é—´"""
        policy = node_config.get("policy", {})
        mode = policy.get("mode", "auto_window")
        
        now = datetime.utcnow()
        kl_tz = pytz.timezone("Asia/Kuala_Lumpur")
        now_kl = now.replace(tzinfo=pytz.UTC).astimezone(kl_tz)
        
        if mode == "auto_window":
            work_hours = policy.get("work_hours", {"start": "09:30", "end": "21:30"})
            quiet_hours = policy.get("quiet_hours", {"start": "22:00", "end": "08:00"})
            
            start_time = datetime.strptime(work_hours["start"], "%H:%M").time()
            end_time = datetime.strptime(work_hours["end"], "%H:%M").time()
            
            current_time = now_kl.time()
            
            # æ£€æŸ¥æ˜¯å¦åœ¨å·¥ä½œæ—¶é—´å†…
            if start_time <= current_time <= end_time:
                # åœ¨å·¥ä½œæ—¶é—´å†…ï¼Œå¯ä»¥ç«‹å³å‘é€
                jitter = policy.get("jitter_seconds", [3, 15])
                import random
                delay_seconds = random.uniform(jitter[0], jitter[1])
                scheduled_at = now + timedelta(seconds=delay_seconds)
            else:
                # ä¸åœ¨å·¥ä½œæ—¶é—´å†…ï¼Œå»¶è¿Ÿåˆ°ä¸‹ä¸€ä¸ªå·¥ä½œæ—¶æ®µ
                next_day = now_kl.replace(hour=int(start_time.hour), 
                                        minute=int(start_time.minute), 
                                        second=0, microsecond=0)
                if current_time > end_time:
                    next_day += timedelta(days=1)
                
                scheduled_at = next_day.astimezone(pytz.UTC).replace(tzinfo=None)
        
        elif mode == "relative":
            delay_minutes = policy.get("relative_minutes", 0)
            scheduled_at = now + timedelta(minutes=delay_minutes)
        
        else:
            scheduled_at = now  # ç«‹å³æ‰§è¡Œ
        
        self.context.scheduled_at = scheduled_at
        
        return {"ctx.scheduled_at": scheduled_at.isoformat()}

class SendWhatsAppMessageProcessor(NodeProcessor):
    """WhatsApp æ¶ˆæ¯å‘é€èŠ‚ç‚¹"""
    
    def __init__(self, db: Session, context: WorkflowContext):
        super().__init__(db, context)
        self.whatsapp_service = WhatsAppService()
    
    def _calculate_send_delay(self, message: str, delay_config: Dict[str, Any]) -> float:
        """
        è®¡ç®—å‘é€å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
        
        Args:
            message: è¦å‘é€çš„æ¶ˆæ¯å†…å®¹
            delay_config: å»¶è¿Ÿé…ç½®
                - enable_smart_delay: æ˜¯å¦å¯ç”¨æ™ºèƒ½å»¶è¿Ÿ (é»˜è®¤: False)
                - base_delay: åŸºç¡€å»¶è¿Ÿç§’æ•° (é»˜è®¤: 1)
                - delay_per_char: æ¯å­—ç¬¦å¢åŠ çš„æ¯«ç§’æ•° (é»˜è®¤: 50)
                - max_delay: æœ€å¤§å»¶è¿Ÿç§’æ•° (é»˜è®¤: 10)
        
        Returns:
            å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œå¦‚æœæœªå¯ç”¨æ™ºèƒ½å»¶è¿Ÿåˆ™è¿”å› 0.0
        """
        if not delay_config.get("enable_smart_delay", False):
            return 0.0
        
        message_length = len(message) if message else 0
        base_delay_ms = delay_config.get("base_delay", 1) * 1000
        delay_per_char_ms = delay_config.get("delay_per_char", 50)
        max_delay_ms = delay_config.get("max_delay", 10) * 1000
        
        # è®¡ç®—æ€»å»¶è¿Ÿæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        calculated_delay_ms = base_delay_ms + (message_length * delay_per_char_ms)
        
        # é™åˆ¶æœ€å¤§å»¶è¿Ÿ
        final_delay_ms = min(calculated_delay_ms, max_delay_ms)
        
        return final_delay_ms / 1000.0  # è½¬æ¢ä¸ºç§’
    
    async def _get_media_urls_from_identifiers(self, media_uuids: List[str], folder_names: List[str], user_id: int) -> List[str]:
        """
        æ ¹æ®åª’ä½“UUIDå’Œæ–‡ä»¶å¤¹åç§°è·å–åª’ä½“æ–‡ä»¶URL
        
        Args:
            media_uuids: åª’ä½“æ–‡ä»¶UUIDåˆ—è¡¨
            folder_names: æ–‡ä»¶å¤¹åç§°åˆ—è¡¨
            user_id: ç”¨æˆ·ID
            
        Returns:
            List[str]: åª’ä½“æ–‡ä»¶URLåˆ—è¡¨
        """
        try:
            from app.db.models import MediaFile
            from app.services import supabase as supabase_service
            from app.core.config import settings
            
            media_urls = []
            
            # è·å–å•ä¸ªåª’ä½“æ–‡ä»¶
            if media_uuids:
                media_files = self.db.query(MediaFile).filter(
                    MediaFile.id.in_(media_uuids),
                    MediaFile.user_id == user_id
                ).all()
                
                for media_file in media_files:
                    # ç”Ÿæˆç­¾åURL
                    relative_path = media_file.filepath.replace(f"{settings.SUPABASE_BUCKET}/", "", 1)
                    signed_url = await supabase_service.get_signed_url_for_file(relative_path)
                    if signed_url:
                        media_urls.append(signed_url)
                        print(f"    ğŸ“ æ·»åŠ åª’ä½“æ–‡ä»¶: {media_file.filename}")
            
            # è·å–æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰åª’ä½“æ–‡ä»¶
            if folder_names:
                for folder_name in folder_names:
                    folder_media = self.db.query(MediaFile).filter(
                        MediaFile.user_id == user_id,
                        MediaFile.folder == folder_name,
                        MediaFile.filename != ".keep"  # æ’é™¤.keepæ–‡ä»¶
                    ).all()
                    
                    for media_file in folder_media:
                        relative_path = media_file.filepath.replace(f"{settings.SUPABASE_BUCKET}/", "", 1)
                        signed_url = await supabase_service.get_signed_url_for_file(relative_path)
                        if signed_url:
                            media_urls.append(signed_url)
                            print(f"    ğŸ“ æ·»åŠ æ–‡ä»¶å¤¹åª’ä½“: {folder_name}/{media_file.filename}")
            
            return media_urls
            
        except Exception as e:
            logger.error(f"Failed to get media URLs from identifiers: {e}")
            return []
    
    async def execute(self, node_config: Dict[str, Any]) -> Dict[str, Any]:
        """å‘é€ WhatsApp æ¶ˆæ¯"""
        # ğŸ”§ ä¿®å¾©ï¼šå¾ data å­—æ®µç²å–é…ç½®ï¼Œèˆ‡å…¶ä»–ç¯€é»ä¿æŒä¸€è‡´
        node_data = node_config.get("data", {})
        
        to = node_data.get("to", "") or node_config.get("to", "")
        message = node_data.get("message", "") or node_config.get("message", "")
        dedupe = node_data.get("dedupe", node_config.get("dedupe", {"window_minutes": 1}))
        retries = node_data.get("retries", node_config.get("retries", {"max": 3, "backoff": [2, 5, 15]}))
        
        print(f"ğŸ“¤ SendWhatsApp ç¯€é»é–‹å§‹åŸ·è¡Œ:")
        print(f"  åˆå§‹é…ç½® - to: '{to}', message: '{message}'")
        print(f"  node_data keys: {list(node_data.keys())}")
        # print(f"  context keys: {list(self.context.__dict__.keys())}") # Remove verbose context keys print
        
        # è§£æå˜é‡å’Œè‡ªåŠ¨å¡«å…… 'to' å­—æ®µ
        send_mode = node_data.get("send_mode", "trigger_number")
        
        if send_mode == "specified_number":
            to = node_data.get("to_number", "")
            print(f"  ä½¿ç”¨æŒ‡å®šå·ç å‘é€: {to}")
        elif send_mode == "trigger_number":
            customer = self.context.db.get("customer")
            if customer:
                to = customer.phone
                print(f"  ä½¿ç”¨è§¦å‘å·ç å‘é€ (è‡ªåŠ¨å¡«å……): {to}")
            else:
                print(f"  âŒ æ‰¾ä¸åˆ°å®¢æˆ·ä¿¡æ¯ï¼Œæ— æ³•è‡ªåŠ¨å¡«å……æ”¶ä»¶äºº")
        else:
            # å›é€€åˆ°å…¶ä»–æƒ…å†µï¼Œä¾‹å¦‚å¦‚æœ `to` å­—æ®µåŒ…å«å˜é‡
            if not to or "{db.phone}" in to or "{trigger_ai.output.phone}" in to: # Add trigger_ai.output.phone to check
                customer = self.context.db.get("customer")
                if customer:
                    if not to:
                        to = customer.phone
                        print(f"  è‡ªå‹•å¡«å……æ”¶ä»¶äºº: {to}")
                    else:
                        # Apply generic variable parsing for 'to' field
                        to = self._resolve_variable_from_context(to)
                        print(f"  æ›¿æ›è®Šé‡æ”¶ä»¶äºº: {to}")
                else:
                    print(f"  âŒ æ‰¾ä¸åˆ°å®¢æˆ¶ä¿¡æ¯ï¼Œç„¡æ³•å¡«å……æ”¶ä»¶äºº")
        
        # ğŸ”§ ä¿®å¾©ï¼šæ”¹å–„ AI å›å¾©æ–‡æœ¬çš„è®€å–é‚è¼¯
        # ç»Ÿä¸€ä½¿ç”¨æ–°çš„å˜é‡è§£æå‡½æ•°æ¥å¤„ç† message å­—æ®µ
        # print(f"  ğŸ” è§£ææ¶ˆæ¯å˜é‡å‰: '{message}'") # Remove verbose pre-resolution message print
        message = self._resolve_variable_from_context(message)
        # print(f"  ğŸ” è§£ææ¶ˆæ¯å˜é‡å: '{message}'") # Remove verbose post-resolution message print
        
        # å¦‚æœ message ä»ç„¶ä¸ºç©ºæˆ–æœªè§£æï¼Œåˆ™æŒ‰ä¼˜å…ˆçº§ä»ä¸Šä¸‹æ–‡è·å–
        if not message:
            # ä¼˜å…ˆä»ä¸Šä¸‹æ–‡çš„ message_content è·å–ï¼Œè¿™æ˜¯æ¨¡æ¿èŠ‚ç‚¹é€šå¸¸ä¼šè®¾ç½®çš„
            context_message_content = self.context.get("message_content", "")
            if context_message_content:
                message = context_message_content
                print(f"  âœ… ä½¿ç”¨ä¸Šä¸‹æ–‡ message_content: '{message}'")
            else:
                # å…¶æ¬¡å›é€€åˆ° AI èŠ‚ç‚¹çš„ reply_text
                ai_ctx = self.context.get("ai", {}) # Fallback to generic 'ai' context
                ai_reply_obj = ai_ctx.get("reply", {})
                ai_reply_text_fallback = ai_reply_obj.get("reply_text", "")

                if ai_reply_text_fallback:
                    message = ai_reply_text_fallback
                    print(f"  âœ… ä½¿ç”¨ AI å›å¾© (fallback): '{message}'")
                else:
                    # æœ€çµ‚ä»æœªæ‰¾åˆ°æ¶ˆæ¯ï¼Œæ‹‹å‡ºéŒ¯èª¤è€Œéä½¿ç”¨é»˜èªå›é€€
                    logger.error(f"Failed to resolve message content for SendWhatsAppMessage node {node_config.get('id')}")
                    raise ValueError("Message content cannot be resolved.")
        
        print(f"  æœ€çµ‚åƒæ•¸ - to: '{to}', message: '{message}'")
        
        if not to:
            print(f"âŒ æ”¶ä»¶äººä¸ºç©ºï¼Œæ— æ³•å‘é€ WhatsApp æ¶ˆæ¯ã€‚")
            logger.error("Recipient 'to' field is empty, cannot send WhatsApp message.")
            return {"ctx.message_id": "failed", "ctx.sent_at": datetime.utcnow().isoformat(), "error": "Recipient is empty"}

        # å»é‡æ£€æŸ¥
        print(f"ğŸ” æª¢æŸ¥å»é‡...")
        should_dedupe = self._should_dedupe(to, message, dedupe)
        print(f"  å»é‡çµæœ: {'âš ï¸ è¢«å»é‡' if should_dedupe else 'âœ… å¯ç™¼é€'}")
        
        if should_dedupe:
            print(f"âŒ æ¶ˆæ¯è¢«å»é‡ï¼Œä¸ç™¼é€åˆ° {to}")
            logger.info(f"Message deduplicated for {to}")
            return {"ctx.message_id": "deduplicated", "ctx.sent_at": datetime.utcnow().isoformat()}
        
        # è·å–æ™ºèƒ½å»¶è¿Ÿé…ç½®
        delay_config = {
            "enable_smart_delay": node_data.get("enable_smart_delay", False),
            "base_delay": node_data.get("base_delay", 1),
            "delay_per_char": node_data.get("delay_per_char", 50),
            "max_delay": node_data.get("max_delay", 10)
        }
        
        # è®¡ç®—å‘é€å»¶è¿Ÿ
        send_delay = self._calculate_send_delay(message, delay_config)
        if send_delay > 0:
            print(f"â±ï¸ æ™ºèƒ½å»¶è¿Ÿ: {send_delay:.2f}ç§’ (æ¶ˆæ¯é•¿åº¦: {len(message)}å­—ç¬¦)")
            await asyncio.sleep(send_delay)
        else:
            print(f"ğŸš€ ç«‹å³å‘é€ (æ™ºèƒ½å»¶è¿Ÿæœªå¯ç”¨)")

        # å‘é€æ¶ˆæ¯
        print(f"ğŸ“¤ é–‹å§‹ç™¼é€ WhatsApp æ¶ˆæ¯...")
        for attempt in range(retries.get("max", 1)):
            try:
                print(f"  å˜—è©¦ {attempt + 1}/{retries.get('max', 1)}")
                
                # ç²å–ç”¨æˆ¶IDç”¨æ–¼èº«ä»½é©—è­‰
                customer = self.context.db.get("customer")
                trigger = self.context.get("trigger_data", {})
                # ä¼˜å…ˆä½¿ç”¨ customer.user_idï¼Œæ²¡æœ‰åˆ™å›é€€åˆ° trigger ä¸­çš„ user_id
                user_id = customer.user_id if customer else trigger.get("user_id")
                print(f"  ç”¨æˆ¶ID: {user_id}")
                
                if not user_id:
                    raise ValueError("Cannot send WhatsApp message: user_id is required")
                
                print(f"  èª¿ç”¨ WhatsApp æœå‹™...")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰åª’ä½“éœ€è¦å‘é€
                ai_reply = self.context.ai.get("reply", {})
                media_uuids = ai_reply.get("media_uuids", [])
                folder_names = ai_reply.get("folder_names", [])
                media_settings = ai_reply.get("media_settings", {})
                
                print(f"  åª’ä½“ä¿¡æ¯: UUIDs={media_uuids}, Folders={folder_names}, Settings={media_settings}")
                
                # æ ¹æ® UUIDs å’Œ folder_names è·å–å®é™…çš„åª’ä½“ URL
                media_urls = []
                if media_uuids or folder_names:
                    media_urls = await self._get_media_urls_from_identifiers(media_uuids, folder_names, user_id)
                    print(f"  ğŸ“ è·å–åˆ° {len(media_urls)} ä¸ªåª’ä½“æ–‡ä»¶URL")
                
                # å¤„ç†åª’ä½“å‘é€
                if media_urls:
                    send_separately = media_settings.get("send_media_separately", False)
                    send_with_caption = media_settings.get("send_with_caption", True)
                    delay_between_media = media_settings.get("delay_between_media", False)
                    delay_seconds = media_settings.get("delay_seconds", 2)
                    
                    if send_separately:
                        # åˆ†å¼€å‘é€ï¼šå…ˆå‘é€åª’ä½“ï¼Œå†å‘é€æ–‡æœ¬ï¼ˆç¡®ä¿åª’ä½“å®Œå…¨ä¸Šä¼ åå†å‘é€æ–‡å­—è¯´æ˜ï¼‰
                        print(f"  ğŸ–¼ï¸ åˆ†å¼€å‘é€æ¨¡å¼ï¼šå…ˆå‘é€æ‰€æœ‰åª’ä½“æ–‡ä»¶")
                        
                        # å…ˆå‘é€æ¯ä¸ªåª’ä½“æ–‡ä»¶
                        media_success_count = 0
                        for i, media_url in enumerate(media_urls):
                            try:
                                if delay_between_media and i > 0:
                                    print(f"  â±ï¸ å»¶è¿Ÿ {delay_seconds} ç§’...")
                                    await asyncio.sleep(delay_seconds)
                                
                                print(f"  ğŸ–¼ï¸ å‘é€åª’ä½“ {i+1}/{len(media_urls)}: {media_url}")
                                media_result = await self.whatsapp_service.send_message(
                                    to, "", user_id, media_url=media_url, media_type="image"
                                )
                                print(f"  âœ… åª’ä½“ {i+1} å‘é€è¯·æ±‚å·²æäº¤: {media_result}")
                                
                                # ç­‰å¾…åª’ä½“ä¸Šä¼ å®Œæˆï¼ˆæ ¹æ®æ–‡ä»¶å¤§å°ä¼°ç®—ä¸Šä¼ æ—¶é—´ï¼‰
                                upload_wait_time = 3 + (i * 2)  # åŸºç¡€3ç§’ + æ¯ä¸ªæ–‡ä»¶é¢å¤–2ç§’
                                print(f"  â³ ç­‰å¾…åª’ä½“ {i+1} ä¸Šä¼ å®Œæˆ ({upload_wait_time}ç§’)...")
                                await asyncio.sleep(upload_wait_time)
                                
                                media_success_count += 1
                            except Exception as media_error:
                                print(f"  âŒ åª’ä½“ {i+1} å‘é€å¤±è´¥: {media_error}")
                                # ç»§ç»­å‘é€ä¸‹ä¸€ä¸ªåª’ä½“ï¼Œä¸ä¸­æ–­æ•´ä¸ªæµç¨‹
                        
                        print(f"  ğŸ“Š åª’ä½“å‘é€ç»“æœ: {media_success_count}/{len(media_urls)} æˆåŠŸ")
                        
                        # é¢å¤–ç­‰å¾…æ—¶é—´ç¡®ä¿æ‰€æœ‰åª’ä½“å®Œå…¨ä¸Šä¼ 
                        final_wait_time = 5  # æœ€ç»ˆç­‰å¾…5ç§’
                        print(f"  â³ æœ€ç»ˆç­‰å¾… {final_wait_time} ç§’ç¡®ä¿æ‰€æœ‰åª’ä½“ä¸Šä¼ å®Œæˆ...")
                        await asyncio.sleep(final_wait_time)
                        
                        # æ‰€æœ‰åª’ä½“ä¸Šä¼ å®Œæˆåï¼Œå†å‘é€æ–‡æœ¬æ¶ˆæ¯
                        print(f"  ğŸ“ åª’ä½“ä¸Šä¼ å®Œæˆï¼Œç°åœ¨å‘é€æ–‡æœ¬æ¶ˆæ¯")
                        text_result = await self.whatsapp_service.send_message(to, message, user_id)
                        print(f"  âœ… æ–‡æœ¬æ¶ˆæ¯å‘é€ç»“æœ: {text_result}")
                        
                        result = text_result  # ä½¿ç”¨æ–‡æœ¬æ¶ˆæ¯çš„ç»“æœä½œä¸ºä¸»è¦ç»“æœ
                    else:
                        # ä¸€èµ·å‘é€ï¼šåª’ä½“é™„å¸¦æ–‡æœ¬è¯´æ˜
                        if len(media_urls) == 1:
                            # å•ä¸ªåª’ä½“æ–‡ä»¶ï¼Œé™„å¸¦æ–‡æœ¬
                            caption = message if send_with_caption else ""
                            print(f"  ğŸ–¼ï¸ğŸ“ å‘é€å•ä¸ªåª’ä½“é™„å¸¦æ–‡æœ¬: {media_urls[0]}")
                            result = await self.whatsapp_service.send_message(
                                to, caption, user_id, media_url=media_urls[0], media_type="image"
                            )
                        else:
                            # å¤šä¸ªåª’ä½“æ–‡ä»¶ï¼Œå…ˆå‘é€æ–‡æœ¬ï¼Œå†å‘é€åª’ä½“
                            print(f"  ğŸ“ å¤šåª’ä½“æ¨¡å¼ï¼šå…ˆå‘é€æ–‡æœ¬æ¶ˆæ¯")
                            text_result = await self.whatsapp_service.send_message(to, message, user_id)
                            
                            for i, media_url in enumerate(media_urls):
                                if delay_between_media and i > 0:
                                    print(f"  â±ï¸ å»¶è¿Ÿ {delay_seconds} ç§’...")
                                    await asyncio.sleep(delay_seconds)
                                
                                print(f"  ğŸ–¼ï¸ å‘é€åª’ä½“ {i+1}/{len(media_urls)}: {media_url}")
                                media_result = await self.whatsapp_service.send_message(
                                    to, "", user_id, media_url=media_url, media_type="image"
                                )
                                print(f"  âœ… åª’ä½“ {i+1} å‘é€ç»“æœ: {media_result}")
                            
                            result = text_result
                else:
                    # æ²¡æœ‰åª’ä½“ï¼Œåªå‘é€æ–‡æœ¬
                    result = await self.whatsapp_service.send_message(to, message, user_id)
                
                print(f"  âœ… æœ€ç»ˆå‘é€ç»“æœ: {result}")
                
                # è®°å½•æ¶ˆæ¯åˆ°æ•°æ®åº“
                customer = self.context.db.get("customer")
                if customer:
                    msg = Message(
                        content=message,
                        direction="outbound",
                        customer_id=customer.id,
                        user_id=customer.user_id,
                        ack=0  # å·²å‘é€
                    )
                    self.db.add(msg)
                    self.db.commit()
                    self.db.refresh(msg)
                    
                    # ğŸ†• ä¿å­˜ whatsapp_id
                    if result.get("whatsapp_id"):  # Check if whatsapp_id is present in the result
                        msg.whatsapp_id = result["whatsapp_id"]
                        self.db.add(msg)
                        self.db.commit()
                else:
                    # æ²¡æœ‰ customer æ—¶ï¼Œä»è¿”å›æˆåŠŸä½†ä¸å†™å…¥ messages è¡¨
                    logger.info("Sent message but no customer in context; skipping DB insert")
                
                return {
                    "ctx.message_id": result.get("message_id", "sent"),
                    "ctx.sent_at": datetime.utcnow().isoformat()
                }
                
            except Exception as e:
                print(f"  âŒ ç™¼é€å¤±æ•—: {str(e)}")
                print(f"  éŒ¯èª¤é¡å‹: {type(e).__name__}")
                if attempt < retries.get("max", 1) - 1:
                    backoff_time = retries.get("backoff", [2, 5, 15])[attempt]
                    print(f"  ç­‰å¾… {backoff_time} ç§’å¾Œé‡è©¦...")
                    await asyncio.sleep(backoff_time)
                    continue
                else:
                    print(f"  ğŸš« æ‰€æœ‰é‡è©¦å¤±æ•—ï¼Œæ‹‹å‡ºéŒ¯èª¤")
                    raise e
    
    def _should_dedupe(self, to: str, message: str, dedupe_config: Dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥å»é‡"""
        window_minutes = dedupe_config.get("window_minutes", 1)  # ğŸ”§ æ¸›å°‘åˆ°1åˆ†é˜
        cutoff_time = datetime.utcnow() - timedelta(minutes=window_minutes)
        
        # ğŸ”§ æ”¹é€²å»é‡é‚è¼¯ï¼šè€ƒæ…®è§¸ç™¼æ¶ˆæ¯çš„å·®ç•°
        trigger_data = self.context.get("trigger_data", {})
        trigger_message = trigger_data.get("message", "")
        
        # æŸ¥æ‰¾æœ€è¿‘çš„ç›¸åŒå›è¦†ä¸”è§¸ç™¼æ¶ˆæ¯ä¹Ÿç›¸åŒçš„æƒ…æ³
        recent_messages = self.db.query(Message).filter(
            Message.content == message,
            Message.direction == "outbound",
            Message.timestamp >= cutoff_time
        ).join(Customer).filter(Customer.phone == to).all()
        
        # ğŸ¯ åªæœ‰åœ¨æœ€è¿‘æœ‰å®Œå…¨ç›¸åŒçš„å›è¦†æ™‚æ‰å»é‡
        # å¦‚æœè§¸ç™¼æ¶ˆæ¯ä¸åŒï¼Œå…è¨±ç›¸åŒçš„å›è¦†
        for recent_msg in recent_messages:
            # ä¿®æ­£å»é‡é€»è¾‘ï¼šåªåœ¨æ¶ˆæ¯å†…å®¹å®Œå…¨ä¸€è‡´ä¸”åœ¨å»é‡çª—å£å†…æ‰å»é‡
            # ç§»é™¤é•¿åº¦åˆ¤æ–­ï¼Œå› ä¸ºè¿™ä¼šå¯¼è‡´æ‰€æœ‰é•¿æ¶ˆæ¯éƒ½è¢«å»é‡
            return True  # å‘ç°ç›¸åŒæ¶ˆæ¯ï¼Œå»é‡
        
        return False  # å…è®¸å‘é€

    def _resolve_variable_from_context(self, text: str) -> str:
        """è§£ææ–‡æœ¬ä¸­çš„æ‰€æœ‰ {{variable_path}} å’Œ {variable_path} å˜é‡"""
        if not isinstance(text, str): # Ensure text is a string
            return str(text)

        def get_nested_value(data, path_parts):
            current = data
            for part in path_parts:
                if isinstance(current, dict) and part in current:
                    current = current[part]
                elif isinstance(current, object) and hasattr(current, part):
                    current = getattr(current, part)
                else:
                    return None
            return current

        def replace_match(match):
            var_path = match.group(1).strip() # Extract path inside {{}} or {}
            print(f"  ğŸ” Resolving variable path: {var_path}") # Debug print

            # å°è¯•ä»å„ç§ä¸Šä¸‹æ–‡ä¸­è§£æå˜é‡
            # ä¼˜å…ˆçº§ï¼štrigger_data, actor, db.customer, ai.reply, é€šç”¨å˜é‡, å…¶ä»–èŠ‚ç‚¹è¾“å‡º

            # 1. ä¼˜å…ˆå°è¯• 'trigger' ç›¸å…³å˜é‡
            if var_path.startswith("trigger."):
                trigger_data = self.context.get("trigger_data", {})
                value = get_nested_value(trigger_data, var_path.split('.')[1:])
                if value is not None:
                    print(f"    - Resolved from trigger: {var_path} -> {value}")
                    return str(value)

            # 2. å°è¯• 'actor' ç›¸å…³å˜é‡
            if var_path.startswith("actor."):
                actor_data = self.context.get("actor", {})
                value = get_nested_value(actor_data, var_path.split('.')[1:])
                if value is not None:
                    print(f"    - Resolved from actor: {var_path} -> {value}")
                    return str(value)

            # 3. å°è¯• 'db.customer' ç›¸å…³å˜é‡æˆ– 'customer.all'
            if var_path.startswith("db.customer."):
                customer_obj = self.context.db.get("customer")
                if customer_obj:
                    value = get_nested_value(customer_obj, var_path.split('.')[2:])
                    if value is not None:
                        print(f"    - Resolved from db.customer: {var_path} -> {value}")
                        return str(value)
            elif var_path == "customer.all":
                customer_obj = self.context.db.get("customer")
                if customer_obj:
                    # å°†æ•´ä¸ªå®¢æˆ·å¯¹è±¡ï¼ˆåŒ…æ‹¬ custom_fieldsï¼‰è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²
                    customer_data = customer_obj.__dict__.copy()
                    customer_data.pop('_s-instance_state', None)
                    
                    # å¦‚æœ custom_fields æ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºå­—å…¸
                    if isinstance(customer_data.get('custom_fields'), str):
                        try:
                            customer_data['custom_fields'] = json.loads(customer_data['custom_fields'])
                        except json.JSONDecodeError:
                            pass # ä¿æŒåŸæ ·ï¼Œå¦‚æœä¸æ˜¯æœ‰æ•ˆ JSON

                    return json.dumps(customer_data, ensure_ascii=False, indent=2)
                return "{}"

            # 4. å°è¯• 'custom_object' ç›¸å…³å˜é‡
            custom_object_match_field = re.match(r"custom_object\.(\d+)\.(\d+)\.([a-zA-Z0-9_.]+)", var_path)
            custom_object_match_all = re.match(r"custom_object\.(\d+)\.all", var_path)

            if custom_object_match_field:
                entity_type_id = int(custom_object_match_field.group(1))
                record_id = int(custom_object_match_field.group(2))
                field_key = custom_object_match_field.group(3)
                
                record_obj = self.db.query(CustomEntityRecord).filter(
                    CustomEntityRecord.entity_type_id == entity_type_id,
                    CustomEntityRecord.id == record_id
                ).first()

                if record_obj and record_obj.data and field_key in record_obj.data:
                    value = get_nested_value(record_obj.data, field_key.split('.'))
                    if value is not None:
                        print(f"    - Resolved from custom_object field: {var_path} -> {value}")
                        return str(value)
            elif custom_object_match_all:
                entity_type_id = int(custom_object_match_all.group(1))
                # ä»ä¸Šä¸‹æ–‡ä¸­è·å–é€‰ä¸­çš„è®°å½•IDï¼Œå¦‚æœå­˜åœ¨çš„è¯
                selected_record_id = self.context.get(f"selectedCustomEntityRecordId_{entity_type_id}")
                
                if selected_record_id:
                    record_obj = self.db.query(CustomEntityRecord).filter(
                        CustomEntityRecord.entity_type_id == entity_type_id,
                        CustomEntityRecord.id == selected_record_id
                    ).first()
                    if record_obj:
                        record_data = record_obj.data.copy() if record_obj.data else {}
                        print(f"    - Resolved from custom_object all: {var_path} -> {record_data}")
                        return json.dumps(record_data, ensure_ascii=False, indent=2)
                print(f"    - Failed to resolve custom_object.all for entity type {entity_type_id}. Record not found or not selected.")
                return "{}"

            # 5. å°è¯• 'ai.reply' ç›¸å…³å˜é‡
            if var_path.startswith("ai.reply."):
                ai_reply = self.context.ai.get("reply", {})
                value = get_nested_value(ai_reply, var_path.split('.')[2:])
                if value is not None:
                    print(f"    - Resolved from ai.reply: {var_path} -> {value}")
                    return str(value)

            # 6. å°è¯•é€šç”¨å˜é‡ (self.context.variables)
            if var_path in self.context.variables:
                value = self.context.variables[var_path]
                print(f"    - Resolved from context.variables: {var_path} -> {value}")
                return str(value)
            
            # 7. å°è¯•è§£æç‰¹å®šèŠ‚ç‚¹è¾“å‡ºå˜é‡ï¼Œä¾‹å¦‚ AI_NODE_ID.output.reply_text
            parts = var_path.split('.')
            if len(parts) >= 2:
                node_id = parts[0]
                output_key = parts[1]
                # æ£€æŸ¥æ˜¯å¦æ˜¯åˆæ³•çš„èŠ‚ç‚¹è¾“å‡ºè·¯å¾„ï¼Œä¾‹å¦‚ AI_123.output
                if output_key == "output" and node_id in self.context.variables:
                    node_output = self.context.variables[node_id]
                    nested_path = parts[2:] # è¿›ä¸€æ­¥çš„åµŒå¥—è·¯å¾„ï¼Œä¾‹å¦‚ reply_text
                    value = get_nested_value(node_output, nested_path)
                    if value is not None:
                        print(f"    - Resolved from node output: {var_path} -> {value}")
                        return str(value)

            # å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œè¿”å›åŸå§‹çš„å˜é‡å ä½ç¬¦
            print(f"    - Failed to resolve: {var_path}")
            return match.group(0) # Return original {{variable}} or {variable} including braces

        # Handle both {{variable}} and {variable} patterns
        text = re.sub(r'''\{\{(.*?)\}\}''', replace_match, text)
        text = re.sub(r'''\{([^{}]*)\}''', replace_match, text)
        return text

class TemplateProcessor(NodeProcessor):
    """æ¨¡æ¿æ¶ˆæ¯èŠ‚ç‚¹ - æ”¯æŒæ•°æ®åº“å˜é‡æŸ¥è¯¢"""
    
    async def execute(self, node_config: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨¡æ¿æ¶ˆæ¯"""
        try:
            # è·å–æ¨¡æ¿é…ç½® - ä»nodeçš„dataå­—æ®µä¸­è·å–
            node_data = node_config.get("data", {})
            template_type = node_data.get("template_type", "text")
            template_name = node_data.get("template_name")
            template_language = node_data.get("template_language", "zh_CN")
            variables = node_data.get("variables", {})
            fallback_template = node_data.get("fallback_template", "æ‚¨å¥½ï¼æ„Ÿè°¢æ‚¨çš„å’¨è¯¢ã€‚")
            
            # print(f"ğŸ” TemplateèŠ‚ç‚¹æ•°æ®ç»“æ„æ£€æŸ¥:") # Remove verbose template node data check
            # print(f"  å®Œæ•´node_config keys: {list(node_config.keys())}") # Remove verbose template node data check
            # print(f"  node_data keys: {list(node_data.keys())}") # Remove verbose template node data check
            # print(f"  variablesç±»å‹: {type(variables)}, å€¼: {variables}") # Remove verbose template node data check
            
            # è§£æå˜é‡
            resolved_variables = {}
            # print(f"ğŸ” æ¨¡æ¿å˜é‡è§£æå¼€å§‹:") # Remove verbose template variable parsing start
            # print(f"  åŸå§‹å˜é‡: {variables}") # Remove verbose original variables print
            for var_key, var_expression in variables.items():
                resolved_value = await self._resolve_variable(var_expression)
                resolved_variables[var_key] = resolved_value
                # print(f"  {var_key}: '{var_expression}' â†’ '{resolved_value}'") # Remove verbose individual variable resolution print
            # print(f"  è§£æç»“æœ: {resolved_variables}") # Remove verbose resolved variables print
            
            # WhatsApp æ¨¡æ¿æ¶ˆæ¯
            if template_type == "whatsapp" and template_name:
                return {
                    "template_data": {
                        "template_name": template_name,
                        "template_language": template_language,
                        "variables": resolved_variables
                    },
                    "fallback_text": self._apply_template(fallback_template, resolved_variables),
                    "message_content": self._apply_template(fallback_template, resolved_variables),
                    "message_type": "template"
                }
            else:
                # æ™®é€šæ–‡æœ¬æ¶ˆæ¯
                # print(f"ğŸ“ åº”ç”¨æ¨¡æ¿:") # Remove verbose template application start
                # print(f"  æ¨¡æ¿: '{fallback_template}'") # Remove verbose template print
                # print(f"  å˜é‡: {resolved_variables}") # Remove verbose variables print
                message_text = self._apply_template(fallback_template, resolved_variables)
                # print(f"  ç»“æœ: '{message_text}'") # Remove verbose result print
                return {
                    "ai.reply.reply_text": message_text,
                    "message_content": message_text,
                    "message_type": "text"
                }
                
        except Exception as e:
            logger.error(f"æ¨¡æ¿å¤„ç†å¤±è´¥: {e}")
            return {
                "ai.reply.reply_text": "æŠ±æ­‰ï¼Œç³»ç»Ÿå‡ºç°é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚",
                "message_type": "text"
            }
    
    async def _resolve_variable(self, expression: str) -> str:
        """è§£æå˜é‡è¡¨è¾¾å¼"""
        if not expression or not isinstance(expression, str):
            return str(expression)
        
        # ç§»é™¤åŒèŠ±æ‹¬å·
        if expression.startswith("{{") and expression.endswith("}}"):
            expression = expression[2:-2].strip()
        
        # è§£æä¸åŒç±»å‹çš„å˜é‡
        if expression.startswith("trigger."):
            return self._resolve_trigger_variable(expression[8:])
        elif expression.startswith("db."):
            return await self._resolve_db_variable(expression[3:])
        elif expression.startswith("ai."):
            return self._resolve_ai_variable(expression[3:])
        else:
            # ç›´æ¥è¿”å›å­—é¢å€¼
            return expression
    
    def _resolve_trigger_variable(self, field: str) -> str:
        """è§£æè§¦å‘å™¨å˜é‡"""
        trigger_data = self.context.get("trigger_data", {})
        
        # ğŸ”§ ä¿®å¾©è®Šé‡æ˜ å°„å•é¡Œ
        if field == "content":
            # trigger_data ä¸­ä½¿ç”¨ "message"ï¼Œä½†æ¨¡æ¿æœŸæœ› "content"
            return str(trigger_data.get("message", ""))
        elif field == "name":
            return str(trigger_data.get("name", ""))
        elif field == "phone":
            return str(trigger_data.get("phone", ""))
        elif field == "timestamp":
            return str(trigger_data.get("timestamp", ""))
        else:
            # å›é€€åˆ°åŸå§‹é‚è¼¯
            return str(trigger_data.get(field, ""))
    
    async def _resolve_db_variable(self, path: str) -> str:
        """è§£ææ•°æ®åº“å˜é‡"""
        try:
            # è§£æè·¯å¾„ ä¾‹å¦‚: "customer.name" æˆ– "customer.phone"
            parts = path.split(".")
            if len(parts) < 2:
                return ""
            
            table_name = parts[0]
            field_name = parts[1]
            
            if table_name == "customer":
                customer = self.context.db.get("customer")
                if customer and hasattr(customer, field_name):
                    value = getattr(customer, field_name)
                    return str(value) if value is not None else ""
            
            return ""
        except Exception as e:
            logger.error(f"æ•°æ®åº“å˜é‡è§£æå¤±è´¥: {e}")
            return ""
    
    def _resolve_ai_variable(self, field: str) -> str:
        """è§£æAIå˜é‡"""
        ai_data = self.context.get("ai", {})
        return str(ai_data.get(field, ""))
    
    def _apply_template(self, template: str, resolved_variables: dict) -> str:
        """åº”ç”¨å˜é‡åˆ°æ¨¡æ¿ - resolved_variablesåº”è¯¥æ˜¯è§£æåçš„å®é™…å€¼"""
        result = template
        
        # print(f"ğŸ”§ æ¨¡æ¿æ›¿æ¢è¯¦æƒ…:") # Remove verbose template replacement details
        # print(f"  åŸå§‹æ¨¡æ¿: '{template}'") # Remove verbose template replacement details
        # print(f"  è§£æåå˜é‡: {resolved_variables}") # Remove verbose template replacement details
        
        # resolved_variablesçš„æ ¼å¼åº”è¯¥æ˜¯: {'1': 'Debug User', '2': '601168208639', '3': 'å†æ¬¡æµ‹è¯•å˜é‡'}
        # ä½†æ˜¯æ¨¡æ¿ä¸­çš„å ä½ç¬¦æ˜¯: {{trigger.name}}, {{trigger.content}} ç­‰
        # 
        # è¿™é‡Œæœ‰ä¸€ä¸ªè®¾è®¡é—®é¢˜ï¼šæˆ‘ä»¬éœ€è¦çŸ¥é“å“ªä¸ªkeyå¯¹åº”å“ªä¸ªåŸå§‹å˜é‡è¡¨è¾¾å¼
        # 
        # å½“å‰çš„è§£å†³æ–¹æ¡ˆï¼šå…ˆå°è¯•ä¸€ç§æ›´ç›´æ¥çš„æ–¹å¼ - ç›´æ¥è§£ææ¨¡æ¿ä¸­çš„å˜é‡è¡¨è¾¾å¼
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ‰¾åˆ°æ¨¡æ¿ä¸­çš„æ‰€æœ‰ {{...}} å ä½ç¬¦å¹¶é€ä¸€æ›¿æ¢
        import re
        
        def replace_variable(match):
            var_expr = match.group(0)  # å®Œæ•´çš„ {{trigger.name}} è¡¨è¾¾å¼
            # è§£æè¿™ä¸ªå˜é‡è¡¨è¾¾å¼
            try:
                # å»æ‰ {{ }}
                inner_expr = var_expr[2:-2].strip()
                if inner_expr.startswith("trigger."):
                    field = inner_expr[8:]  # å»æ‰ "trigger."
                    trigger_data = self.context.get("trigger_data", {})
                    
                    # ğŸ”§ ä¿®å¾©å­—æ®µæ˜ å°„
                    if field == "content":
                        value = str(trigger_data.get("message", ""))  # message è€Œä¸æ˜¯ content
                    else:
                        value = str(trigger_data.get(field, ""))
                    
                    # print(f"    æ›¿æ¢ {var_expr} â†’ '{value}'") # Remove verbose individual variable replacement print
                    return value
                # å¯ä»¥æ‰©å±•æ”¯æŒå…¶ä»–ç±»å‹çš„å˜é‡
                return var_expr  # å¦‚æœä¸èƒ½è§£æï¼Œä¿æŒåŸæ ·
            except Exception as e:
                print(f"    æ›¿æ¢å¤±è´¥ {var_expr}: {e}")
                return var_expr
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢æ‰€æœ‰ {{...}} è¡¨è¾¾å¼
        result = re.sub(r'''\{\{(.*?)\}\}''', replace_variable, template)
        
        # print(f"  æœ€ç»ˆç»“æœ: '{result}'") # Remove verbose final result print
        
        return result

class SendTelegramMessageProcessor(NodeProcessor):
    """Telegram æ¶ˆæ¯å‘é€èŠ‚ç‚¹"""
    
    def __init__(self, db: Session, context: WorkflowContext):
        super().__init__(db, context)
        self.telegram_service = TelegramService()
    
    async def execute(self, node_config: Dict[str, Any]) -> Dict[str, Any]:
        """å‘é€ Telegram æ¶ˆæ¯"""
        node_data = node_config.get("data", {})
        
        send_mode = node_data.get("send_mode", "trigger_number")
        to = ""
        bot_token = node_data.get("bot_token")
        chat_id = node_data.get("chat_id") # For telegram_chat_id mode
        message = node_data.get("message", "") or node_config.get("message", "")
        
        print(f"ğŸ“¤ SendTelegram ç¯€é»é–‹å§‹åŸ·è¡Œ:")
        print(f"  åˆå§‹é…ç½® - send_mode: '{send_mode}', message: '{message}'")
        
        if send_mode == "specified_number":
            to = node_data.get("to_number", "") # è¿™é‡Œå®é™…ä¸Šæ˜¯ chat_id
            print(f"  ä½¿ç”¨æŒ‡å®šå·ç å‘é€ (Telegram Chat ID): {to}")
        elif send_mode == "telegram_chat_id":
            to = chat_id # ç›´æ¥ä½¿ç”¨é…ç½®ä¸­çš„ chat_id
            print(f"  ä½¿ç”¨ Telegram Chat ID å‘é€: {to}")
        elif send_mode == "trigger_number":
            # å¯¹äº Telegramï¼Œè§¦å‘å·ç å¯èƒ½ä¸æ˜¯ç›´æ¥çš„ chat_idï¼Œéœ€è¦é¢å¤–é€»è¾‘æˆ–æ˜ å°„
            # æš‚æ—¶å‡è®¾ trigger_data.phone å¯ä»¥ä½œä¸º chat_idï¼Œä½†è¿™å¯èƒ½ä¸å‡†ç¡®
            trigger_data = self.context.get("trigger_data", {})
            to = trigger_data.get("phone", "") # å‡è®¾è§¦å‘å™¨çš„ phone å¯ä»¥ä½œä¸º chat_id
            print(f"  ä½¿ç”¨è§¦å‘å·ç å‘é€ (å‡è®¾ä¸º Chat ID): {to}")
        
        # è§£ææ¶ˆæ¯å˜é‡
        if not message or "{ai.reply.reply_text}" in message:
            message_content = self.context.get("message_content", "")
            ai_reply_text = self.context.get("ai.reply.reply_text", "")
            
            ai_reply_obj = self.context.get("ai.reply", {})
            if isinstance(ai_reply_obj, dict):
                ai_reply_text = ai_reply_obj.get("reply_text", ai_reply_text)
            
            if not message:
                if ai_reply_text:
                    message = ai_reply_text
                elif message_content:
                    message = message_content
                else:
                    message = "Hi! We received your message."
            else:
                if ai_reply_text:
                    message = message.replace("{ai.reply.reply_text}", ai_reply_text)
        
        print(f"  æœ€çµ‚åƒæ•¸ - to: '{to}', message: '{message}', bot_token: '{bot_token[:5]}...'")
        
        if not to or not bot_token:
            raise ValueError("Missing recipient (chat_id) or bot_token for Telegram message")
        
        # ç²å–ç”¨æˆ¶IDç”¨æ–¼èº«ä»½é©—è­‰ (å¦‚æœé€šè¿‡ç”¨æˆ·ä¼šè¯å‘é€)
        customer = self.context.db.get("customer")
        trigger = self.context.get("trigger_data", {})
        user_id = customer.user_id if customer else trigger.get("user_id")
        
        # å‘é€æ¶ˆæ¯
        print(f"ğŸš€ é–‹å§‹ç™¼é€ Telegram æ¶ˆæ¯...")
        try:
            result = await self.telegram_service.send_message(chat_id=to, message=message, user_id=user_id, bot_token=bot_token)
            print(f"  âœ… ç™¼é€çµæœ: {result}")
            
            # è®°å½•æ¶ˆæ¯åˆ°æ•°æ®åº“
            if customer:
                msg = Message(
                    content=message,
                    direction="outbound",
                    customer_id=customer.id,
                    user_id=customer.user_id,
                    ack=0  # å·²å‘é€
                )
                self.db.add(msg)
                self.db.commit()
            else:
                logger.info("Sent Telegram message but no customer in context; skipping DB insert")
            
            return {
                "ctx.message_id": result.get("telegram_message_id", "sent"),
                "ctx.sent_at": datetime.utcnow().isoformat()
            }
        except Exception as e:
            logger.error(f"Failed to send Telegram message: {e}")
            raise e

class GuardrailValidatorProcessor(NodeProcessor):
    """åˆè§„æ£€æŸ¥èŠ‚ç‚¹"""
    
    async def execute(self, node_config: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œåˆè§„æ£€æŸ¥"""
        checks = node_config.get("checks", {})
        blocked_keywords = checks.get("blocked_keywords", [])
        url_whitelist = checks.get("url_whitelist", [])
        
        # è·å–è¦æ£€æŸ¥çš„å†…å®¹
        ai_reply = self.context.get("ai.reply", {})
        reply_text = ai_reply.get("reply_text", "")
        
        # å…³é”®è¯æ£€æŸ¥
        for keyword in blocked_keywords:
            if keyword.lower() in reply_text.lower():
                return {"pass_or_fail_branch": "fail"}
        
        # URL æ£€æŸ¥ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        import re
        urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', reply_text)
        if urls and url_whitelist:
            for url in urls:
                if not any(allowed in url for allowed in url_whitelist):
                    return {"pass_or_fail_branch": "fail"}
        
        return {"pass_or_fail_branch": "pass"}


def _get_var_value_from_context(context: WorkflowContext, var_path: str):
    # æ”¯æŒ: trigger.X, db.customer.field, ai.field
    try:
        if var_path.startswith('trigger.'):
            return context.get('trigger_data', {}).get(var_path.split('.', 1)[1])
        if var_path.startswith('db.customer.'):
            customer = context.db.get('customer')
            if customer:
                return getattr(customer, var_path.split('.', 2)[2], None)
            return None
        if var_path.startswith('ai.'):
            return context.get('ai', {}).get(var_path.split('.', 1)[1])
        # fallback to variables
        return context.get(var_path)
    except Exception:
        return None


def evaluate_jsonlogic(expression: dict, context_vars: dict) -> bool:
    # minimal jsonlogic subset
    if not isinstance(expression, dict):
        return bool(expression)
    if '==' in expression:
        a, b = expression['==']
        if isinstance(a, dict) and 'var' in a:
            a = context_vars.get(a['var'])
        if isinstance(b, dict) and 'var' in b:
            b = context_vars.get(b['var'])
        return a == b
    if '!=' in expression:
        a, b = expression['!=']
        if isinstance(a, dict) and 'var' in a:
            a = context_vars.get(a['var'])
        if isinstance(b, dict) and 'var' in b:
            b = context_vars.get(b['var'])
        return a != b
    if 'and' in expression:
        return all(evaluate_jsonlogic(e, context_vars) for e in expression['and'])
    if 'or' in expression:
        return any(evaluate_jsonlogic(e, context_vars) for e in expression['or'])
    if 'var' in expression:
        return context_vars.get(expression['var'])
    return False


class ConditionProcessor(NodeProcessor):
    """Condition èŠ‚ç‚¹ï¼Œæ”¯æŒå¯è§†åŒ–æ¡ä»¶æ„å»ºå™¨æˆ– JSONLogic"""
    
    def _get_field_value(self, field_path: str, customer=None):
        """è·å–å­—æ®µå€¼ï¼Œæ”¯æŒ db.customer.* å’Œ custom_fields.*"""
        if field_path.startswith('db.customer.'):
            field_name = field_path.replace('db.customer.', '')
            if customer:
                if field_name == 'custom_fields':
                    return customer.custom_fields or {}
                else:
                    return getattr(customer, field_name, None)
        elif field_path.startswith('custom_fields.'):
            field_key = field_path.replace('custom_fields.', '')
            if customer and customer.custom_fields:
                custom_fields = customer.custom_fields if isinstance(customer.custom_fields, dict) else json.loads(customer.custom_fields or '{}')
                return custom_fields.get(field_key)
        elif field_path.startswith('trigger.'):
            field_name = field_path.replace('trigger.', '')
            trigger = self.context.get('trigger_data', {})
            return trigger.get(field_name)
        elif field_path.startswith('ai.'):
            field_name = field_path.replace('ai.', '')
            ai_ctx = self.context.get('ai', {}) or {}
            return ai_ctx.get(field_name)
        return None
    
    def _evaluate_condition(self, condition: Dict[str, Any], customer=None) -> bool:
        """è¯„ä¼°å•ä¸ªæ¡ä»¶"""
        field = condition.get('field', '')
        operator = condition.get('operator', '==')
        value = condition.get('value', '')
        
        if not field:
            return False
            
        actual_value = self._get_field_value(field, customer)
        
        try:
            # å¤„ç†ä¸åŒçš„æ“ä½œç¬¦
            if operator == '==':
                return str(actual_value) == str(value)
            elif operator == '!=':
                return str(actual_value) != str(value)
            elif operator == '>':
                return float(actual_value or 0) > float(value or 0)
            elif operator == '>=':
                return float(actual_value or 0) >= float(value or 0)
            elif operator == '<':
                return float(actual_value or 0) < float(value or 0)
            elif operator == '<=':
                return float(actual_value or 0) <= float(value or 0)
            elif operator == 'contains':
                return str(value).lower() in str(actual_value or '').lower()
            elif operator == 'starts_with':
                return str(actual_value or '').lower().startswith(str(value).lower())
            elif operator == 'ends_with':
                return str(actual_value or '').lower().endswith(str(value).lower())
            elif operator == 'is_empty':
                return not actual_value or str(actual_value).strip() == ''
            elif operator == 'is_not_empty':
                return actual_value and str(actual_value).strip() != ''
            elif operator == 'between':
                if ',' in str(value):
                    min_val, max_val = str(value).split(',', 1)
                    actual_num = float(actual_value or 0)
                    return float(min_val.strip() or 0) <= actual_num <= float(max_val.strip() or 0)
                return False
            elif operator == 'days_ago':
                if actual_value:
                    from datetime import datetime, timedelta
                    try:
                        if isinstance(actual_value, str):
                            actual_date = datetime.fromisoformat(actual_value.replace('Z', '+00:00'))
                        else:
                            actual_date = actual_value
                        days_diff = (datetime.utcnow() - actual_date).days
                        return days_diff == int(value or 0)
                    except:
                        return False
                return False
            elif operator == 'days_from_now':
                if actual_value:
                    from datetime import datetime, timedelta
                    try:
                        if isinstance(actual_value, str):
                            actual_date = datetime.fromisoformat(actual_value.replace('Z', '+00:00'))
                        else:
                            actual_date = actual_value
                        days_diff = (actual_date - datetime.utcnow()).days
                        return days_diff == int(value or 0)
                    except:
                        return False
                return False
            else:
                return False
        except (ValueError, TypeError) as e:
            logger.warning(f"Condition evaluation error for {field} {operator} {value}: {e}")
            return False
    
    async def execute(self, node_config: Dict[str, Any]) -> Dict[str, Any]:
        node_data = node_config.get('data', {})
        mode = node_data.get('mode', 'visual')
        # fallback_output: å½“æ¡ä»¶è¯„ä¼°å‘ç”Ÿå¼‚å¸¸æˆ–å‡ºç°ä¸å¯é¢„æœŸé”™è¯¯æ—¶çš„å›é€€å€¼ã€‚
        # - 'false' (é»˜è®¤)ï¼šåœ¨è¯„ä¼°å¼‚å¸¸æ—¶è§†ä¸ºæ¡ä»¶ä¸æˆç«‹ï¼Œä¸æ²¿ true åˆ†æ”¯æ‰§è¡Œã€‚
        # - 'true'ï¼šåœ¨è¯„ä¼°å¼‚å¸¸æ—¶è§†ä¸ºæ¡ä»¶æˆç«‹ï¼Œæ²¿ true åˆ†æ”¯æ‰§è¡Œã€‚
        # æ³¨æ„ï¼šæ­£å¸¸çš„ true/false åˆ¤å®šä¸ä¼šä½¿ç”¨è¯¥å›é€€å­—æ®µï¼Œåªæœ‰åœ¨è¯„ä¼°æŠ›å¼‚å¸¸æˆ–å¼•æ“æ— æ³•è®¡ç®—ç»“æœæ—¶æ‰ä¼šç”¨åˆ°ã€‚
        fallback_output = node_data.get('fallback_output', 'false')
        
        customer = self.context.db.get('customer')
        result = False
        
        try:
            if mode == 'jsonlogic':
                # JSONLogic æ¨¡å¼ - ä¿æŒåŸæœ‰é€»è¾‘
                expr_raw = node_data.get('jsonlogic') or node_data.get('json_logic')
                if isinstance(expr_raw, str):
                    expr = json.loads(expr_raw)
                else:
                    expr = expr_raw or {}
                
                # æ„å»ºä¸Šä¸‹æ–‡å˜é‡
                ctx_vars = {}
                trigger = self.context.get('trigger_data', {})
                for k, v in trigger.items():
                    ctx_vars[f'trigger.{k}'] = v
                
                if customer:
                    for attr in ['id', 'name', 'phone', 'email', 'status', 'stage_id', 'budget_min', 'budget_max', 'preferred_location', 'move_in_date', 'unread_count', 'updated_at', 'last_timestamp', 'last_follow_up_time']:
                        ctx_vars[f'db.customer.{attr}'] = getattr(customer, attr, None)
                    
                    # æ·»åŠ  custom_fields æ”¯æŒ
                    if customer.custom_fields:
                        custom_fields = customer.custom_fields if isinstance(customer.custom_fields, dict) else json.loads(customer.custom_fields or '{}')
                        for key, value in custom_fields.items():
                            ctx_vars[f'custom_fields.{key}'] = value
                
                ai_ctx = self.context.get('ai', {}) or {}
                for k, v in ai_ctx.items():
                    ctx_vars[f'ai.{k}'] = v
                
                result = evaluate_jsonlogic(expr, ctx_vars)
            else:
                # å¯è§†åŒ–æ¡ä»¶æ„å»ºå™¨æ¨¡å¼
                conditions = node_data.get('conditions', [])
                logic_operator = node_data.get('logicOperator', 'AND')
                
                if not conditions:
                    result = False
                else:
                    condition_results = []
                    for condition in conditions:
                        condition_result = self._evaluate_condition(condition, customer)
                        condition_results.append(condition_result)
                        logger.info(f"Condition {condition.get('field')} {condition.get('operator')} {condition.get('value')} = {condition_result}")
                    
                    # æ ¹æ®é€»è¾‘æ“ä½œç¬¦ç»„åˆç»“æœ
                    if logic_operator == 'OR':
                        result = any(condition_results)
                    else:  # AND
                        result = all(condition_results)
                    
                    logger.info(f"Final condition result ({logic_operator}): {result}")
                        
        except Exception as e:
            logger.exception(f'Condition evaluation error: {e}')
            result = fallback_output == 'true'
        
        branch = 'true' if result else 'false'
        logger.info(f"Condition node {node_config.get('id', 'unknown')} evaluated to: {branch}")
        
        # namespaced branch key so multiple condition nodes don't conflict
        return {f'__branch__{node_config.get("id")}': branch}

class WorkflowEngine:
    """å·¥ä½œæµå¼•æ“"""
    
    def __init__(self, db: Session):
        self.db = db
        self.processors = {
            "MessageTrigger": MessageTriggerProcessor,
            "AI": AIProcessor,
            "Condition": ConditionProcessor,
            "UpdateDB": UpdateDBProcessor,
            "Delay": DelayProcessor,
            "SendWhatsAppMessage": SendWhatsAppMessageProcessor,
            "SendTelegramMessage": SendTelegramMessageProcessor, # æ·»åŠ  Telegram æ¶ˆæ¯å‘é€å¤„ç†å™¨
            "Template": TemplateProcessor,
            "GuardrailValidator": GuardrailValidatorProcessor
        }
    
    async def execute_workflow(self, workflow_id: int, trigger_data: Dict[str, Any]) -> WorkflowExecution:
        """æ‰§è¡Œå·¥ä½œæµ"""
        print(f"\nğŸ”„ å·¥ä½œæµåŸ·è¡Œé–‹å§‹ - ID: {workflow_id}")
        print(f"  è§¸ç™¼è³‡æ–™: {trigger_data}")
        
        # è·å–å·¥ä½œæµå®šä¹‰
        workflow = self.db.query(Workflow).filter(
            Workflow.id == workflow_id,
            Workflow.is_active == True
        ).first()
        
        if not workflow:
            print(f"  âŒ å·¥ä½œæµ {workflow_id} æœªæ‰¾åˆ°æˆ–æœªå•Ÿç”¨")
            raise ValueError(f"Workflow {workflow_id} not found or not active")
        
        print(f"  âœ… å·¥ä½œæµæ‰¾åˆ°: {workflow.name}")
        print(f"  ç¯€é»æ•¸é‡: {len(workflow.nodes)}")
        print(f"  é‚Šæ•¸é‡: {len(workflow.edges)}")
        
        # åˆ›å»ºæ‰§è¡Œè®°å½•
        execution = WorkflowExecution(
            workflow_id=workflow_id,
            status="running",
            triggered_by=trigger_data.get("trigger_type", "manual"),
            execution_data=trigger_data,
            user_id=workflow.user_id
        )
        self.db.add(execution)
        self.db.commit()
        self.db.refresh(execution)
        
        # åˆ›å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
        context = WorkflowContext()
        context.set("trigger_data", trigger_data)
        
        try:
            # æŒ‰ç…§ edges å®šä¹‰çš„é¡ºåºæ‰§è¡ŒèŠ‚ç‚¹
            nodes_dict = {node["id"]: node for node in workflow.nodes}
            edges = workflow.edges
            
            # æ‰¾åˆ°èµ·å§‹èŠ‚ç‚¹ï¼ˆé€šå¸¸æ˜¯ç¬¬ä¸€ä¸ª edge çš„æºèŠ‚ç‚¹ï¼‰
            if not edges:
                raise ValueError("Workflow has no edges defined")
            
            # å¤„ç† edges åˆ—è¡¨ï¼Œæ„å»º edge_map å¹¶é€‰æ‹©åˆé€‚çš„èµ·å§‹èŠ‚ç‚¹
            edge_map = {}
            incoming_count = {}
            # ç»Ÿä¸€å¤„ç†ä¸¤ç§ edges æ ¼å¼ï¼ˆdict åˆ—è¡¨æˆ–æ•°ç»„å¯¹ï¼‰
            for edge in edges:
                if isinstance(edge, dict):
                    source = edge.get('source')
                    target = edge.get('target')
                else:
                    # æ—§æ ¼å¼: [source, target, ...]
                    if len(edge) < 2:
                        continue
                    source, target = edge[0], edge[1]

                if source is None or target is None:
                    continue

                edge_map.setdefault(source, []).append(target)
                incoming_count[target] = incoming_count.get(target, 0) + 1
                incoming_count.setdefault(source, incoming_count.get(source, 0))

            # é¦–å…ˆå°è¯•æ‰¾åˆ° MessageTrigger ç±»å‹çš„èŠ‚ç‚¹ä½œä¸ºå…¥å£
            start_node_id = None
            for n in workflow.nodes:
                if n.get('type') == 'MessageTrigger':
                    start_node_id = n.get('id')
                    break

            # å¦‚æœæ²¡æœ‰ MessageTriggerï¼Œåˆ™é€‰å…¥åº¦ä¸º 0 çš„èŠ‚ç‚¹
            if not start_node_id:
                for nid in nodes_dict.keys():
                    if incoming_count.get(nid, 0) == 0:
                        start_node_id = nid
                        break

            # æœ€åå›é€€åˆ°ç¬¬ä¸€ä¸ª edge çš„ sourceï¼ˆå…¼å®¹ï¼‰
            if not start_node_id:
                first_edge = edges[0]
                if isinstance(first_edge, dict):
                    start_node_id = first_edge.get('source')
                else:
                    start_node_id = first_edge[0] if len(first_edge) > 0 else None

            current_node_id = start_node_id
            
            # æ‰§è¡ŒèŠ‚ç‚¹åºåˆ—
            while current_node_id:
                if current_node_id not in nodes_dict:
                    break
                
                node = nodes_dict[current_node_id]
                await self._execute_node(execution, node, context)
                
                # æ ¹æ®èŠ‚ç‚¹ç±»å‹å’Œç»“æœå†³å®šä¸‹ä¸€ä¸ªèŠ‚ç‚¹
                next_nodes = edge_map.get(current_node_id, [])
                
                if not next_nodes:
                    break
                
                # æ”¯æŒåŸºäº Condition çš„ true/false åˆ†æ”¯è·¯ç”±ï¼š
                # - å¦‚æœå½“å‰èŠ‚ç‚¹æœ‰æ˜¾å¼åˆ†æ”¯åŒ–çš„ outgoing edgesï¼ˆedge id åŒ…å« true/false æˆ– edge dict æœ‰ sourceHandleï¼‰ï¼Œ
                #   åˆ™åªåœ¨èƒ½æ‰¾åˆ°ä¸å½“å‰åˆ†æ”¯åŒ¹é…çš„ edge æ—¶ç»§ç»­æ‰§è¡Œå¯¹åº”ç›®æ ‡ï¼›å¦åˆ™åœæ­¢æ‰§è¡Œï¼ˆä¸å›é€€åˆ°ç¬¬ä¸€ä¸ª targetï¼‰ã€‚
                # - å¦‚æœæ²¡æœ‰ä»»ä½•åˆ†æ”¯åŒ–çš„ outgoing edgesï¼Œåˆ™ä¿ç•™å…¼å®¹è¡Œä¸ºï¼Œå–ç¬¬ä¸€ä¸ª targetã€‚
                branch_key = f'__branch__{current_node_id}'
                branch_val = context.get(branch_key)

                # æŸ¥æ‰¾è¯¥èŠ‚ç‚¹çš„æ‰€æœ‰ outgoing edge å¯¹è±¡ï¼ˆä½¿ç”¨åŸå§‹ edges åˆ—è¡¨ä»¥è·å–å…ƒä¿¡æ¯ï¼‰
                outgoing_edges = []
                if edges and isinstance(edges, list):
                    for e in edges:
                        try:
                            if isinstance(e, dict):
                                if e.get('source') == current_node_id:
                                    outgoing_edges.append(e)
                            else:
                                # å…¼å®¹æ—§æ ¼å¼æ•°ç»„ [source, target]
                                if len(e) >= 2 and e[0] == current_node_id:
                                    outgoing_edges.append({'source': e[0], 'target': e[1], 'sourceHandle': e[2] if len(e) > 2 else None}) # ç¡®ä¿å…¼å®¹æ—§æ ¼å¼å¹¶è·å– sourceHandle
                        except Exception:
                            continue

                # åˆ¤æ–­æ˜¯å¦å­˜åœ¨çœŸæ­£çš„åˆ†æ”¯åŒ– edgeï¼ˆé€šè¿‡ sourceHandle ä¸º true/false æ ‡è¯†ï¼‰
                has_conditional_branch_edges = any(
                    isinstance(e, dict) and e.get('sourceHandle') in ['true', 'false']
                    for e in outgoing_edges
                )

                selected_next = None
                if has_conditional_branch_edges:
                    # ä»…åœ¨ branch_val å¯ç”¨æ—¶å°è¯•åŒ¹é…æ¡ä»¶åˆ†æ”¯
                    if branch_val is not None:
                        for e in outgoing_edges:
                            try:
                                # match by explicit sourceHandle for true/false branches
                                if isinstance(e, dict) and e.get('sourceHandle') in ['true', 'false']:
                                    if str(e.get('sourceHandle')).lower() == str(branch_val).lower():
                                        selected_next = e.get('target')
                                        break
                            except Exception:
                                continue
                    # å¦‚æœå­˜åœ¨æ¡ä»¶åˆ†æ”¯è¾¹ä½†æœªæ‰¾åˆ°åŒ¹é…ï¼Œåˆ™åœæ­¢æ‰§è¡Œï¼ˆä¸å›é€€ï¼‰
                    if not selected_next:
                        current_node_id = None
                    else:
                        current_node_id = selected_next
                else:
                    # éæ¡ä»¶åˆ†æ”¯ï¼šå–ç¬¬ä¸€ä¸ª targetï¼ˆåŒ…æ‹¬ sourceHandle ä¸º "out" ç­‰æƒ…å†µï¼‰
                    current_node_id = next_nodes[0] if next_nodes else None
            
            # æ ‡è®°æ‰§è¡Œå®Œæˆ
            execution.status = "completed"
            execution.completed_at = datetime.utcnow()
            self.db.commit()
            
            return execution
            
        except Exception as e:
            execution.status = "failed"
            execution.error_message = str(e)
            execution.completed_at = datetime.utcnow()
            self.db.commit()
            logger.error(f"Workflow execution failed: {str(e)}")
            raise e
    
    async def _execute_node(self, execution: WorkflowExecution, node: Dict[str, Any], context: WorkflowContext):
        """æ‰§è¡Œå•ä¸ªèŠ‚ç‚¹"""
        node_id = node["id"]
        node_type = node["type"]
        
        print(f"\n  ğŸ“¦ åŸ·è¡Œç¯€é» - ID: {node_id}, é¡å‹: {node_type}")
        print(f"    ç¯€é»é…ç½®: {node}")
        
        # åˆ›å»ºæ­¥éª¤æ‰§è¡Œè®°å½•
        step = WorkflowStepExecution(
            execution_id=execution.id,
            node_id=node_id,
            node_type=node_type,
            status="running",
            input_data=node
        )
        self.db.add(step)
        self.db.commit()
        self.db.refresh(step)
        
        try:
            start_time = datetime.utcnow()
            
            # è·å–å¤„ç†å™¨ç±»
            processor_class = self.processors.get(node_type)
            if not processor_class:
                # æ ¹æ® channel åŠ¨æ€é€‰æ‹©å¤„ç†å™¨
                if node_type == "SendMessage" and node.get("data", {}).get("channel") == "telegram":
                    processor_class = SendTelegramMessageProcessor
                elif node_type == "SendMessage" and node.get("data", {}).get("channel") == "whatsapp":
                    processor_class = SendWhatsAppMessageProcessor
                else:
                    print(f"    âŒ ä¸æ”¯æ´çš„ç¯€é»é¡å‹: {node_type}")
                    raise ValueError(f"Unsupported node type: {node_type}")
            
            print(f"    ğŸš€ å‰µå»ºè™•ç†å™¨: {processor_class.__name__}")
            
            # åˆ›å»ºå¤„ç†å™¨å¹¶æ‰§è¡Œ
            processor = processor_class(self.db, context)
            print(f"    â³ é–‹å§‹åŸ·è¡Œç¯€é»...")
            output_data = await processor.execute(node)
            # print(f"    âœ… ç¯€é»åŸ·è¡Œå®Œæˆï¼Œè¼¸å‡º: {output_data}")
            
            # æ›´æ–°ä¸Šä¸‹æ–‡
            context.update_from_dict(output_data)
            print(f"    ğŸ“ ä¸Šä¸‹æ–‡å·²æ›´æ–°")
            
            # è®°å½•æ‰§è¡Œç»“æœ
            end_time = datetime.utcnow()
            step.status = "completed"
            step.output_data = output_data
            step.completed_at = end_time
            step.duration_ms = int((end_time - start_time).total_seconds() * 1000)
            
            # è®°å½•åˆ†æ”¯ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            branch_key = f"__branch__{node_id}"
            if context.get(branch_key):
                step.branch_taken = context.get(branch_key)

            self.db.commit()
            
        except Exception as e:
            step.status = "failed"
            step.error_message = str(e)
            step.completed_at = datetime.utcnow()
            self.db.commit()
            raise e
